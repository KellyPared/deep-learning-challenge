{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8ZArEAwpNRLcjesWysyFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KellyPared/deep-learning-challenge/blob/main/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "jtQAKUl7xNO2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "67bCQJpsxLbu"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd \n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import and read the charity_data.csv.\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "NbXLN0DkX0eH",
        "outputId": "2bc29d0b-d3eb-47c3-862c-e629303cb9bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7dc777a9-7807-40e6-8941-a8d637bd9e62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dc777a9-7807-40e6-8941-a8d637bd9e62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7dc777a9-7807-40e6-8941-a8d637bd9e62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7dc777a9-7807-40e6-8941-a8d637bd9e62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtOpvWDy6rs",
        "outputId": "08464262-3901-49fd-9730-625111d19a44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['EIN', 'NAME', 'APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION',\n",
              "       'USE_CASE', 'ORGANIZATION', 'STATUS', 'INCOME_AMT',\n",
              "       'SPECIAL_CONSIDERATIONS', 'ASK_AMT', 'IS_SUCCESSFUL'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#there is a fairly equal amount of is successful\n",
        "application_df['IS_SUCCESSFUL'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYHnkkTO7Zf_",
        "outputId": "e3169fc6-bbcc-4335-d160-3a7c7a67b734"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    18261\n",
              "0    16038\n",
              "Name: IS_SUCCESSFUL, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: \"Wants a tool that can help it select the applicants for funding with the best chance of success..\"\n",
        "\n",
        "*   What variable(s) are the target(s) for your model?\n",
        "*   What variable(s) are the feature(s) for your model?\n",
        "\n",
        "\n",
        "### Target Variable is \"Is Successful\"\n",
        "### The other variables(Except EIN and NAME) are the features.\n"
      ],
      "metadata": {
        "id": "PXTyIPqt3E1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df.drop(['EIN', 'NAME'], axis=1, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "K9H9vh9yxRV6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the number of unique values for each column\n",
        "for col in application_df.columns:\n",
        "    unique_vals = application_df[col].nunique()\n",
        "    #print(f\"{col}: {unique_vals}\")\n",
        "    print(\"{:<23}: {}\".format(col, unique_vals))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQI7TF6m0_SU",
        "outputId": "044a6afb-fd99-47c3-c349-f1ac9594f1a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPLICATION_TYPE       : 17\n",
            "AFFILIATION            : 6\n",
            "CLASSIFICATION         : 71\n",
            "USE_CASE               : 5\n",
            "ORGANIZATION           : 4\n",
            "STATUS                 : 2\n",
            "INCOME_AMT             : 9\n",
            "SPECIAL_CONSIDERATIONS : 2\n",
            "ASK_AMT                : 8747\n",
            "IS_SUCCESSFUL          : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "# In ml, this column can be used as a feature to predict whether an organization will be successful in receiving funding.\n",
        "app_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "print(app_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJMow3c1xRdr",
        "outputId": "72ac1cfb-c371-46a6-a792-c1db203f242a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T3     27037\n",
            "T4      1542\n",
            "T6      1216\n",
            "T5      1173\n",
            "T19     1065\n",
            "T8       737\n",
            "T7       725\n",
            "T10      528\n",
            "T9       156\n",
            "T13       66\n",
            "T12       27\n",
            "T2        16\n",
            "T25        3\n",
            "T14        3\n",
            "T29        2\n",
            "T15        2\n",
            "T17        1\n",
            "Name: APPLICATION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the number of unique values for each column\n",
        "for col in application_df.columns:\n",
        "    unique_vals = application_df[col].nunique()\n",
        "\n",
        "    #For columns that have more than 10 unique values, determine the number of data points for each unique value.\n",
        "    #anything else. just print\n",
        "    \n",
        "    if unique_vals > 10:\n",
        "        print(\"Unique values for column '{}' (total: {}):\".format(col, unique_vals))\n",
        "        print(application_df[col].value_counts())\n",
        "        print(\" \")\n",
        "\n",
        "    else:\n",
        "        print(\"Unique Values less than 10\")\n",
        "        print(\"{:<23}: {}\".format(col, unique_vals))\n",
        "        print(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpQFvf7QJKM",
        "outputId": "764778cb-54c0-4d81-8499-140bd18d5149"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values for column 'APPLICATION_TYPE' (total: 17):\n",
            "T3     27037\n",
            "T4      1542\n",
            "T6      1216\n",
            "T5      1173\n",
            "T19     1065\n",
            "T8       737\n",
            "T7       725\n",
            "T10      528\n",
            "T9       156\n",
            "T13       66\n",
            "T12       27\n",
            "T2        16\n",
            "T25        3\n",
            "T14        3\n",
            "T29        2\n",
            "T15        2\n",
            "T17        1\n",
            "Name: APPLICATION_TYPE, dtype: int64\n",
            " \n",
            "Unique Values less than 10\n",
            "AFFILIATION            : 6\n",
            " \n",
            "Unique values for column 'CLASSIFICATION' (total: 71):\n",
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "         ...  \n",
            "C4120        1\n",
            "C8210        1\n",
            "C2561        1\n",
            "C4500        1\n",
            "C2150        1\n",
            "Name: CLASSIFICATION, Length: 71, dtype: int64\n",
            " \n",
            "Unique Values less than 10\n",
            "USE_CASE               : 5\n",
            " \n",
            "Unique Values less than 10\n",
            "ORGANIZATION           : 4\n",
            " \n",
            "Unique Values less than 10\n",
            "STATUS                 : 2\n",
            " \n",
            "Unique Values less than 10\n",
            "INCOME_AMT             : 9\n",
            " \n",
            "Unique Values less than 10\n",
            "SPECIAL_CONSIDERATIONS : 2\n",
            " \n",
            "Unique values for column 'ASK_AMT' (total: 8747):\n",
            "5000        25398\n",
            "10478           3\n",
            "15583           3\n",
            "63981           3\n",
            "6725            3\n",
            "            ...  \n",
            "5371754         1\n",
            "30060           1\n",
            "43091152        1\n",
            "18683           1\n",
            "36500179        1\n",
            "Name: ASK_AMT, Length: 8747, dtype: int64\n",
            " \n",
            "Unique Values less than 10\n",
            "IS_SUCCESSFUL          : 2\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 17 different T types of the application type; T-codes might correspond to different types of activities that the organization performs, such as training and technical assistance, consulting, research and evaluation, information dissemination\n"
      ],
      "metadata": {
        "id": "yt2K_gqlYZ1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a cutoff value that captures the majority of the variation in the data while still allowing you to bin the less common values into a single category."
      ],
      "metadata": {
        "id": "0ZR8f8ysZnBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "\n",
        "# The items below 500 are less frequent\n",
        "#A good rule of thumb is to choose a cutoff value that reduces the number \n",
        "# of unique values in the column to a manageable number\n",
        "cutoff = 500\n",
        "\n",
        "# Get the counts of each application type\n",
        "type_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "\n",
        "# application types less frequently than the cutoff\n",
        "application_types_to_replace = list(type_counts[type_counts < cutoff].index)\n",
        "\n",
        "# Print the types to be replaced\n",
        "print(application_types_to_replace)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm1d-Hu2xRgc",
        "outputId": "27c1e2fe-fdc9-477f-e9cc-4437bd8fe7e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T9', 'T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4wnc0KlxRjH",
        "outputId": "58800967-65a8-479d-f5ec-5913919a78b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This information is important because it can help us to decide how to handle infrequent values in the CLASSIFICATION column. One common approach is to bin the infrequent values together into a single category. This can help to reduce the dimensionality of the data and"
      ],
      "metadata": {
        "id": "7dNCUk8Cb1Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at CLASSIFICATION value counts for \n",
        "#use this information to determine which values occur frequently and which values occur infrequently\n",
        "\n",
        "classification_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classification_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz7SUaxcxRlm",
        "outputId": "8bef1266-ee22-442b-e9b1-2aff5de3bc8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: CLASSIFICATION, Length: 71, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "\n",
        "classification_counts_over_1 = classification_counts[classification_counts > 1]\n",
        "print(classification_counts_over_1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPCOWYeqb8NV",
        "outputId": "03538407-791e-4ae2-e89b-178b9c1b4dd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "C7000      777\n",
            "C1700      287\n",
            "C4000      194\n",
            "C5000      116\n",
            "C1270      114\n",
            "C2700      104\n",
            "C2800       95\n",
            "C7100       75\n",
            "C1300       58\n",
            "C1280       50\n",
            "C1230       36\n",
            "C1400       34\n",
            "C7200       32\n",
            "C2300       32\n",
            "C1240       30\n",
            "C8000       20\n",
            "C7120       18\n",
            "C1500       16\n",
            "C1800       15\n",
            "C6000       15\n",
            "C1250       14\n",
            "C8200       11\n",
            "C1238       10\n",
            "C1278       10\n",
            "C1235        9\n",
            "C1237        9\n",
            "C7210        7\n",
            "C2400        6\n",
            "C1720        6\n",
            "C4100        6\n",
            "C1257        5\n",
            "C1600        5\n",
            "C1260        3\n",
            "C2710        3\n",
            "C0           3\n",
            "C3200        2\n",
            "C1234        2\n",
            "C1246        2\n",
            "C1267        2\n",
            "C1256        2\n",
            "Name: CLASSIFICATION, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "cutoff2 = 300\n",
        "# use the variable name `classifications_to_replace`\n",
        "# Get the counts of each application type\n",
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# Identify the application types that occur less frequently than the cutoff\n",
        "classifications_to_replace =  list(class_counts[class_counts < cutoff2].index)\n",
        "\n",
        "classifications_to_replace \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts7-rzyntdKV",
        "outputId": "2eb64119-65ef-4e0b-9d23-dd96e23a029b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C1700',\n",
              " 'C4000',\n",
              " 'C5000',\n",
              " 'C1270',\n",
              " 'C2700',\n",
              " 'C2800',\n",
              " 'C7100',\n",
              " 'C1300',\n",
              " 'C1280',\n",
              " 'C1230',\n",
              " 'C1400',\n",
              " 'C7200',\n",
              " 'C2300',\n",
              " 'C1240',\n",
              " 'C8000',\n",
              " 'C7120',\n",
              " 'C1500',\n",
              " 'C1800',\n",
              " 'C6000',\n",
              " 'C1250',\n",
              " 'C8200',\n",
              " 'C1238',\n",
              " 'C1278',\n",
              " 'C1235',\n",
              " 'C1237',\n",
              " 'C7210',\n",
              " 'C2400',\n",
              " 'C1720',\n",
              " 'C4100',\n",
              " 'C1257',\n",
              " 'C1600',\n",
              " 'C1260',\n",
              " 'C2710',\n",
              " 'C0',\n",
              " 'C3200',\n",
              " 'C1234',\n",
              " 'C1246',\n",
              " 'C1267',\n",
              " 'C1256',\n",
              " 'C2190',\n",
              " 'C4200',\n",
              " 'C2600',\n",
              " 'C5200',\n",
              " 'C1370',\n",
              " 'C1248',\n",
              " 'C6100',\n",
              " 'C1820',\n",
              " 'C1900',\n",
              " 'C1236',\n",
              " 'C3700',\n",
              " 'C2570',\n",
              " 'C1580',\n",
              " 'C1245',\n",
              " 'C2500',\n",
              " 'C1570',\n",
              " 'C1283',\n",
              " 'C2380',\n",
              " 'C1732',\n",
              " 'C1728',\n",
              " 'C2170',\n",
              " 'C4120',\n",
              " 'C8210',\n",
              " 'C2561',\n",
              " 'C4500',\n",
              " 'C2150']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXZNxBq_0y38",
        "outputId": "62096013-2406-4114-ecf7-670be98a32dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Other     1484\n",
              "C7000      777\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "# identify the categorical columns\n",
        "cat_cols = application_df.select_dtypes(include=['object']).columns\n",
        "cat_cols\n"
      ],
      "metadata": {
        "id": "XR6boyCJ1I-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0605bd9-7de2-4f30-fb16-6560f44054df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE',\n",
              "       'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OneHotEncoder\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "encoded_df = pd.DataFrame(enc.fit_transform(application_df[cat_cols]))\n",
        "encoded_df.columns = enc.get_feature_names_out()\n",
        "encoded_df.head()\n",
        "\n",
        "# convert the categorical columns to dummy variables\n",
        "# final_df = pd.get_dummies(application_df, columns=cat_cols)\n",
        "\n",
        "# apply one-hot encoding using pd.get_dummies\n",
        "# final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "gGvPBlyX8ywY",
        "outputId": "7355d3d5-8826-4659-8138-3b7a73368879"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
              "0                     0.0                   1.0                   0.0   \n",
              "1                     0.0                   0.0                   0.0   \n",
              "2                     0.0                   0.0                   0.0   \n",
              "3                     0.0                   0.0                   0.0   \n",
              "4                     0.0                   0.0                   0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
              "0                  0.0                  0.0                  0.0   \n",
              "1                  1.0                  0.0                  0.0   \n",
              "2                  0.0                  0.0                  1.0   \n",
              "3                  1.0                  0.0                  0.0   \n",
              "4                  1.0                  0.0                  0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
              "0                  0.0                  0.0                  0.0   \n",
              "1                  0.0                  0.0                  0.0   \n",
              "2                  0.0                  0.0                  0.0   \n",
              "3                  0.0                  0.0                  0.0   \n",
              "4                  0.0                  0.0                  0.0   \n",
              "\n",
              "   AFFILIATION_CompanySponsored  ...  INCOME_AMT_1-9999  \\\n",
              "0                           0.0  ...                0.0   \n",
              "1                           0.0  ...                1.0   \n",
              "2                           1.0  ...                0.0   \n",
              "3                           1.0  ...                0.0   \n",
              "4                           0.0  ...                0.0   \n",
              "\n",
              "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                     0.0                       0.0                 0.0   \n",
              "1                     0.0                       0.0                 0.0   \n",
              "2                     0.0                       0.0                 0.0   \n",
              "3                     1.0                       0.0                 0.0   \n",
              "4                     0.0                       1.0                 0.0   \n",
              "\n",
              "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0               0.0                     0.0              0.0   \n",
              "1               0.0                     0.0              0.0   \n",
              "2               0.0                     0.0              0.0   \n",
              "3               0.0                     0.0              0.0   \n",
              "4               0.0                     0.0              0.0   \n",
              "\n",
              "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
              "0                0.0                       1.0                       0.0  \n",
              "1                0.0                       1.0                       0.0  \n",
              "2                0.0                       1.0                       0.0  \n",
              "3                0.0                       1.0                       0.0  \n",
              "4                0.0                       1.0                       0.0  \n",
              "\n",
              "[5 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35302e12-02e0-4512-9667-64495fb1cd5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35302e12-02e0-4512-9667-64495fb1cd5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35302e12-02e0-4512-9667-64495fb1cd5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35302e12-02e0-4512-9667-64495fb1cd5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core import application\n",
        "#merge one-hot encoder and drop originals\n",
        "\n",
        "application_df = application_df.merge(encoded_df, left_index=True, right_index =True)\n",
        "application_df = application_df.drop(cat_cols,1)\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "MngCIxay0IeV",
        "outputId": "45198e7c-26a0-4f66-d579-ee84945caaab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-fba0bef732c8>:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  application_df = application_df.drop(cat_cols,1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                     0.0   \n",
              "1       1   108590              1                     0.0   \n",
              "2       1     5000              0                     0.0   \n",
              "3       1     6692              1                     0.0   \n",
              "4       1   142590              1                     0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                   1.0                   0.0                  0.0   \n",
              "1                   0.0                   0.0                  1.0   \n",
              "2                   0.0                   0.0                  0.0   \n",
              "3                   0.0                   0.0                  1.0   \n",
              "4                   0.0                   0.0                  1.0   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                  0.0                  0.0                  0.0  ...   \n",
              "1                  0.0                  0.0                  0.0  ...   \n",
              "2                  0.0                  1.0                  0.0  ...   \n",
              "3                  0.0                  0.0                  0.0  ...   \n",
              "4                  0.0                  0.0                  0.0  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                0.0                     0.0                       0.0   \n",
              "1                1.0                     0.0                       0.0   \n",
              "2                0.0                     0.0                       0.0   \n",
              "3                0.0                     1.0                       0.0   \n",
              "4                0.0                     0.0                       1.0   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                 0.0               0.0                     0.0   \n",
              "1                 0.0               0.0                     0.0   \n",
              "2                 0.0               0.0                     0.0   \n",
              "3                 0.0               0.0                     0.0   \n",
              "4                 0.0               0.0                     0.0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0              0.0                0.0                       1.0   \n",
              "1              0.0                0.0                       1.0   \n",
              "2              0.0                0.0                       1.0   \n",
              "3              0.0                0.0                       1.0   \n",
              "4              0.0                0.0                       1.0   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                       0.0  \n",
              "1                       0.0  \n",
              "2                       0.0  \n",
              "3                       0.0  \n",
              "4                       0.0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f57c9416-2bdf-475b-a717-68413a413e4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f57c9416-2bdf-475b-a717-68413a413e4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f57c9416-2bdf-475b-a717-68413a413e4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f57c9416-2bdf-475b-a717-68413a413e4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slX6sR8j9xyC",
        "outputId": "d4b852db-d83f-4ae8-c46a-e10a55a5190b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['STATUS', 'ASK_AMT', 'IS_SUCCESSFUL', 'APPLICATION_TYPE_Other',\n",
              "       'APPLICATION_TYPE_T10', 'APPLICATION_TYPE_T19', 'APPLICATION_TYPE_T3',\n",
              "       'APPLICATION_TYPE_T4', 'APPLICATION_TYPE_T5', 'APPLICATION_TYPE_T6',\n",
              "       'APPLICATION_TYPE_T7', 'APPLICATION_TYPE_T8',\n",
              "       'AFFILIATION_CompanySponsored', 'AFFILIATION_Family/Parent',\n",
              "       'AFFILIATION_Independent', 'AFFILIATION_National', 'AFFILIATION_Other',\n",
              "       'AFFILIATION_Regional', 'CLASSIFICATION_C1000', 'CLASSIFICATION_C1200',\n",
              "       'CLASSIFICATION_C2000', 'CLASSIFICATION_C2100', 'CLASSIFICATION_C3000',\n",
              "       'CLASSIFICATION_C7000', 'CLASSIFICATION_Other',\n",
              "       'USE_CASE_CommunityServ', 'USE_CASE_Heathcare', 'USE_CASE_Other',\n",
              "       'USE_CASE_Preservation', 'USE_CASE_ProductDev',\n",
              "       'ORGANIZATION_Association', 'ORGANIZATION_Co-operative',\n",
              "       'ORGANIZATION_Corporation', 'ORGANIZATION_Trust', 'INCOME_AMT_0',\n",
              "       'INCOME_AMT_1-9999', 'INCOME_AMT_10000-24999',\n",
              "       'INCOME_AMT_100000-499999', 'INCOME_AMT_10M-50M', 'INCOME_AMT_1M-5M',\n",
              "       'INCOME_AMT_25000-99999', 'INCOME_AMT_50M+', 'INCOME_AMT_5M-10M',\n",
              "       'SPECIAL_CONSIDERATIONS_N', 'SPECIAL_CONSIDERATIONS_Y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split our preproesssed data into our features and target arrays\n",
        "X = application_df.drop('IS_SUCCESSFUL', axis=1).values # remove the target column\n",
        "y = application_df['IS_SUCCESSFUL'].values # set the target column as the target variable\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
      ],
      "metadata": {
        "id": "Kie62IzP1JxZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "Ygy8IpZt-rJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39844a8b-e555-4619-abf2-20834c9ed176"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (25724, 44)\n",
            "y_train shape: (25724,)\n",
            "X_test shape: (8575, 44)\n",
            "y_test shape: (8575,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "QbNeJRDa1Lkf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile, Train and Evaluate the Model\n",
        "Create a neural network model by assigning the number of input features and nodes for each layer using TensorFlow and Keras."
      ],
      "metadata": {
        "id": "QHjRF3fCDIxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#Sequential = layers are stacked on top of each other in sequence\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#the number of input features - this is the length of the training -pick any column\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "print(number_input_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L88ovrqf2TZk",
        "outputId": "32f98949-5e7e-40f0-919b-8ad0f9074e78"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#hidden nodes for each layer pick a random number\n",
        "units_layer1 = 30\n",
        "units_layer2 = 20\n",
        "\n",
        "#the more layers - \n",
        "# First hidden layer\n",
        "model.add(Dense(units=units_layer1, \n",
        "                                activation='relu', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(units=units_layer2, \n",
        "                                activation='relu', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A06CBVgQDKM_",
        "outputId": "b8835097-5382-4532-b0ac-63344d08b572"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 30)                1350      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,991\n",
            "Trainable params: 1,991\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model - \n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Iq6ParogDMLg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the checkpoint file path\n",
        "checkpoint_filepath = 'model_weights.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    period=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "weights = model.get_weights()\n",
        "for i, layer_weights in enumerate(weights):\n",
        "    print(f'Layer {i} weights:')\n",
        "    print(layer_weights)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train,epochs=100,\n",
        "          validation_data=(X_test, y_test),\n",
        "    callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "6VjHEBSTDONl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8817eb-76fd-4588-99d4-50c232c3812f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 weights:\n",
            "[[ 0.04374507 -0.17091711  0.10754123 ... -0.05539891  0.11193019\n",
            "  -0.02577055]\n",
            " [-0.08946584 -0.21575186  0.08470872 ... -0.09094821 -0.04773429\n",
            "   0.07658347]\n",
            " [ 0.01443878  0.205762    0.02468875 ... -0.1482408  -0.15723203\n",
            "   0.19214839]\n",
            " ...\n",
            " [ 0.1336382  -0.16182575  0.04738224 ... -0.07212114  0.23062292\n",
            "   0.164487  ]\n",
            " [-0.26566207 -0.11542235 -0.01903778 ... -0.09049782  0.14805084\n",
            "  -0.2746326 ]\n",
            " [-0.2510138   0.06152624  0.19570225 ...  0.0572089   0.10947552\n",
            "   0.27385142]]\n",
            "Layer 1 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "Layer 2 weights:\n",
            "[[-0.18203087 -0.09047413  0.17967886 -0.16189784 -0.3412123   0.27086914\n",
            "   0.25345713 -0.09195441 -0.17227817  0.07633379  0.28943288 -0.28334883\n",
            "  -0.23110771 -0.09663738 -0.25142416 -0.0862084   0.14129883  0.11056265\n",
            "  -0.15325655  0.19526976]\n",
            " [-0.2982206  -0.11418913  0.32626128 -0.08777624  0.17354387  0.11178607\n",
            "  -0.12797771 -0.04384273  0.25113034  0.21064359  0.12902239 -0.19495276\n",
            "   0.26937938 -0.11119811 -0.07377827 -0.22060251  0.12773019  0.05629072\n",
            "   0.28664517  0.3199237 ]\n",
            " [-0.2605828  -0.285173   -0.24832174 -0.14781415  0.11759567  0.0157882\n",
            "  -0.19732468 -0.01506281 -0.18321176 -0.03420648  0.23424613 -0.32747617\n",
            "  -0.18559012  0.26476544 -0.03933123  0.12144539  0.0984908  -0.08181742\n",
            "   0.20555633 -0.04246315]\n",
            " [-0.25063303  0.2727992  -0.2763127   0.19114172  0.20485628  0.32843107\n",
            "  -0.18666083 -0.02197811 -0.23404679  0.25453496  0.00185928 -0.33804646\n",
            "  -0.22527838  0.04508293 -0.33397853  0.3128364  -0.24262191 -0.17980556\n",
            "  -0.2714463  -0.09775491]\n",
            " [ 0.34257382 -0.24058416  0.23916024 -0.1730451   0.3172146   0.01795289\n",
            "  -0.20095214 -0.32873634  0.11604807  0.22680515 -0.0184333   0.05241588\n",
            "  -0.15023018 -0.33343798  0.13862115  0.17793357  0.22869253 -0.34071216\n",
            "   0.0960761  -0.04407704]\n",
            " [-0.2724282  -0.24994886  0.33644813  0.27590173 -0.31219319  0.11275503\n",
            "  -0.23948579  0.17296416  0.28718483 -0.14180487 -0.24904993 -0.20972748\n",
            "  -0.18247497  0.15436655 -0.11896534  0.08209407  0.22614717 -0.24280097\n",
            "   0.273655    0.22512162]\n",
            " [-0.24078023  0.312858   -0.11631179 -0.24331576 -0.15537526 -0.083065\n",
            "   0.21593755 -0.02129829 -0.30029088  0.33144194  0.21903527 -0.06395471\n",
            "   0.09140825  0.26320225  0.1310477   0.03247431 -0.06858811  0.20463139\n",
            "  -0.08214274  0.03600407]\n",
            " [ 0.03409407  0.19415975 -0.00995374  0.1745184   0.24936992 -0.2914689\n",
            "  -0.17713737  0.32927936  0.08263811  0.1130577   0.24751312  0.02600497\n",
            "  -0.33881727 -0.22104874 -0.1633948   0.15270436  0.03172132  0.1502662\n",
            "  -0.27618486  0.09540415]\n",
            " [ 0.01340693  0.28893256 -0.29284295  0.19374561  0.15910643 -0.04591155\n",
            "  -0.19373901  0.03745237 -0.05811661  0.26674062  0.11282027 -0.2547753\n",
            "  -0.23804986  0.16009569 -0.16722576 -0.32324052  0.33385926  0.28350198\n",
            "   0.2540533   0.20095766]\n",
            " [ 0.10315272  0.06584999 -0.28524074 -0.07242891  0.260338    0.03450528\n",
            "   0.34175372  0.09785733  0.33440298 -0.24611887  0.03208148  0.32837576\n",
            "   0.31658208  0.29747206 -0.11485521  0.23032588  0.03152516  0.04616114\n",
            "   0.34316713 -0.06353679]\n",
            " [ 0.24596244  0.08362868 -0.05675924 -0.22812974 -0.19746368 -0.3037368\n",
            "   0.25741565 -0.29621002 -0.02335909  0.2874753   0.09906414  0.00885463\n",
            "  -0.2578778  -0.08067888  0.07424062 -0.13169172  0.18397677 -0.20074137\n",
            "   0.30149722 -0.09600714]\n",
            " [ 0.04813331  0.20480251 -0.19285941  0.2263524   0.07630357 -0.2972623\n",
            "   0.01506197 -0.10264617  0.27343273  0.19414437  0.01127824 -0.19008742\n",
            "  -0.14449625  0.22074401 -0.1860115  -0.2525313   0.00948784  0.22197473\n",
            "  -0.02389026  0.31623608]\n",
            " [-0.06814453 -0.23910108 -0.04970542 -0.12681293 -0.01356593 -0.25969338\n",
            "   0.06588271  0.10469708 -0.33993605  0.11018473  0.28736794 -0.05269489\n",
            "   0.23182964  0.1633209   0.04113814  0.16473913 -0.18179335 -0.06544679\n",
            "   0.1185016   0.06452087]\n",
            " [ 0.08737889 -0.11229838 -0.2320803   0.18210882  0.3127129   0.18691784\n",
            "   0.07874098 -0.18494318 -0.249637    0.3389756   0.2796681   0.34241956\n",
            "  -0.10054879 -0.17768306 -0.27766132  0.29466832  0.08149421  0.04001886\n",
            "   0.01416537  0.33583874]\n",
            " [-0.24279115  0.06860736 -0.09866853 -0.21555787 -0.05501434  0.21584398\n",
            "   0.04117185 -0.07770109 -0.02822566  0.29143    -0.09839557  0.07129157\n",
            "   0.06796166 -0.14744978 -0.07533172 -0.24219343 -0.21009377  0.16074854\n",
            "   0.18573952  0.19785374]\n",
            " [ 0.25198877 -0.18207309 -0.3375357  -0.10190947 -0.17114386  0.04681823\n",
            "   0.07446477 -0.0267857   0.08621418 -0.08410153 -0.23198457  0.08728018\n",
            "   0.06338111  0.09511712  0.3253265  -0.3091637  -0.1900169   0.00158212\n",
            "  -0.06592664  0.2599848 ]\n",
            " [ 0.02764729 -0.2617913   0.18391633 -0.07511649 -0.3365732   0.13399509\n",
            "  -0.23465967 -0.22316901  0.3153016  -0.20531903 -0.07413706 -0.33695576\n",
            "   0.1075249  -0.01533154 -0.16124092 -0.2615477   0.24252057 -0.16086827\n",
            "   0.12606227 -0.071374  ]\n",
            " [ 0.10035232  0.0090611  -0.14869763 -0.28520778  0.33816904  0.14453045\n",
            "   0.33946353  0.26250648  0.03821269  0.30600673 -0.26069662  0.3442679\n",
            "  -0.22291622 -0.1014995  -0.32491958 -0.09855266  0.02907231 -0.240564\n",
            "  -0.05922821  0.16569918]\n",
            " [ 0.26600462  0.29745167  0.07966104 -0.00655547 -0.18354063  0.15072745\n",
            "  -0.09715159 -0.0652574   0.22334272 -0.16316734 -0.08619273  0.30881155\n",
            "   0.0951823  -0.05107281  0.3288855   0.30229908  0.29288852 -0.09302965\n",
            "  -0.01180047  0.21325588]\n",
            " [ 0.2739281   0.22561306  0.14947158  0.2604931   0.27778494 -0.03063634\n",
            "   0.21106297 -0.34115666 -0.05239928 -0.03573489 -0.24034473  0.28736198\n",
            "   0.19805998  0.32062256  0.20066768 -0.34528387  0.00215074 -0.33992976\n",
            "   0.21791458 -0.21275152]\n",
            " [-0.26192093 -0.12646043  0.07925487 -0.25589275 -0.02637714  0.07988057\n",
            "  -0.02650398 -0.12264393  0.27161598  0.10209307  0.25489956  0.09494707\n",
            "   0.18382442 -0.32331872 -0.13562576 -0.04485348  0.29346353 -0.23190439\n",
            "  -0.01256219 -0.30985093]\n",
            " [-0.30477193  0.01490825  0.16017294  0.04746044  0.0422436  -0.16576135\n",
            "  -0.34595153 -0.33335042 -0.12288129 -0.2647167  -0.07704985  0.10102576\n",
            "  -0.2845312   0.12885615  0.00830513 -0.05351689  0.08262688 -0.22458717\n",
            "  -0.12890099 -0.11996931]\n",
            " [ 0.2286076   0.22008556  0.15010548  0.29805303 -0.33566865  0.20385116\n",
            "  -0.25282392 -0.23633619 -0.07635593 -0.04451519  0.29569417  0.06368348\n",
            "  -0.16598691  0.12166283 -0.1389778   0.14649692  0.30189472  0.31265283\n",
            "  -0.2733361  -0.21045567]\n",
            " [-0.03121769  0.21299863  0.07989553 -0.11294416  0.03306434 -0.17184563\n",
            "   0.2878899  -0.14346048  0.0488289   0.24978596  0.14423394 -0.00084704\n",
            "   0.23939854  0.19666654 -0.33337387  0.30748653  0.0788652  -0.29089117\n",
            "  -0.10745592 -0.23909323]\n",
            " [ 0.1980949  -0.3121444  -0.1348358  -0.25211522  0.11227319  0.04631186\n",
            "   0.14662445 -0.16097027 -0.0914464  -0.04915935 -0.13503805 -0.11939828\n",
            "   0.1942733   0.2613181  -0.12760828  0.03231946  0.13150638 -0.08399028\n",
            "  -0.30363086 -0.11556393]\n",
            " [ 0.08658785  0.06841856  0.31256437 -0.07374054 -0.11640024  0.29970187\n",
            "  -0.2075555  -0.28202772 -0.2981234  -0.3425389   0.18704528  0.19355649\n",
            "  -0.21798232 -0.04820251 -0.05062798 -0.20222668 -0.21117446 -0.23771776\n",
            "   0.0716491   0.19136739]\n",
            " [ 0.32254124  0.1873005  -0.21509595 -0.24711716  0.21576327  0.07876146\n",
            "   0.34519243 -0.07041627 -0.19773135  0.10163924 -0.13145445  0.11980051\n",
            "  -0.18704595  0.24628079  0.11935204  0.13566476 -0.2021421  -0.3350665\n",
            "  -0.13303705  0.1187245 ]\n",
            " [-0.05142522  0.07553715 -0.02880421  0.18071109 -0.03236693 -0.30637237\n",
            "  -0.21659935  0.30135226  0.26863617 -0.06226778  0.21350622  0.02296695\n",
            "   0.2501223   0.33687925 -0.07047671  0.27036476 -0.08495435  0.06403029\n",
            "  -0.08382684  0.26238346]\n",
            " [-0.18786895  0.27813888 -0.01746073 -0.20332456  0.22896957 -0.34096032\n",
            "   0.14617324 -0.2612389   0.02355301  0.0600476  -0.20070024 -0.0785194\n",
            "   0.18330204  0.08088395 -0.05964777 -0.26330623 -0.34029093  0.16396499\n",
            "   0.03540659  0.10916317]\n",
            " [-0.07578093  0.02418789 -0.02055374  0.13765022  0.3346979   0.28607762\n",
            "   0.08137035 -0.02654842 -0.30164605  0.12989628 -0.05631945  0.2638054\n",
            "   0.02189544  0.26424795 -0.296686   -0.15770571  0.03987044 -0.07029033\n",
            "   0.01609161 -0.04732525]]\n",
            "Layer 3 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 4 weights:\n",
            "[[ 0.13899434]\n",
            " [-0.51763666]\n",
            " [ 0.50758165]\n",
            " [-0.41692638]\n",
            " [-0.10868472]\n",
            " [-0.42414433]\n",
            " [-0.31569868]\n",
            " [-0.05569184]\n",
            " [-0.20390439]\n",
            " [ 0.4121651 ]\n",
            " [-0.17354205]\n",
            " [ 0.4743771 ]\n",
            " [-0.27792326]\n",
            " [-0.3330866 ]\n",
            " [ 0.05256867]\n",
            " [ 0.41296005]\n",
            " [-0.42044792]\n",
            " [-0.02103615]\n",
            " [-0.4760021 ]\n",
            " [ 0.46379745]]\n",
            "Layer 5 weights:\n",
            "[0.]\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 17s 19ms/step - loss: 0.5744 - accuracy: 0.7194 - val_loss: 34674.3906 - val_accuracy: 0.4657\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5574 - accuracy: 0.7282 - val_loss: 15088.3047 - val_accuracy: 0.4657\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5528 - accuracy: 0.7281 - val_loss: 9307.5088 - val_accuracy: 0.5343\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5515 - accuracy: 0.7294 - val_loss: 17642.6152 - val_accuracy: 0.5343\n",
            "Epoch 5/100\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5497 - accuracy: 0.7312\n",
            "Epoch 5: saving model to model_weights.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5499 - accuracy: 0.7308 - val_loss: 16155.4434 - val_accuracy: 0.4657\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5490 - accuracy: 0.7317 - val_loss: 25397.7031 - val_accuracy: 0.4657\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7307 - val_loss: 30395.0703 - val_accuracy: 0.4657\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.7313 - val_loss: 979.8032 - val_accuracy: 0.5343\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7319 - val_loss: 12505.8389 - val_accuracy: 0.4657\n",
            "Epoch 10/100\n",
            "787/804 [============================>.] - ETA: 0s - loss: 0.5467 - accuracy: 0.7326\n",
            "Epoch 10: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7325 - val_loss: 22801.5352 - val_accuracy: 0.4657\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7318 - val_loss: 26058.3750 - val_accuracy: 0.5343\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7312 - val_loss: 1161.0420 - val_accuracy: 0.5343\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7329 - val_loss: 1737.7308 - val_accuracy: 0.4657\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7334 - val_loss: 7176.8125 - val_accuracy: 0.5343\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7328\n",
            "Epoch 15: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7328 - val_loss: 9611.8496 - val_accuracy: 0.5343\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7332 - val_loss: 14751.0029 - val_accuracy: 0.4657\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5438 - accuracy: 0.7334 - val_loss: 7344.0483 - val_accuracy: 0.4657\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7332 - val_loss: 6279.3008 - val_accuracy: 0.4657\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7336 - val_loss: 18919.4414 - val_accuracy: 0.5343\n",
            "Epoch 20/100\n",
            "797/804 [============================>.] - ETA: 0s - loss: 0.5435 - accuracy: 0.7328\n",
            "Epoch 20: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7331 - val_loss: 9325.1689 - val_accuracy: 0.5343\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7345 - val_loss: 10442.9229 - val_accuracy: 0.4657\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7345 - val_loss: 9824.8916 - val_accuracy: 0.5343\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7331 - val_loss: 11597.1885 - val_accuracy: 0.5343\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7325 - val_loss: 8936.1152 - val_accuracy: 0.4657\n",
            "Epoch 25/100\n",
            "792/804 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.7353\n",
            "Epoch 25: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7353 - val_loss: 2842.9333 - val_accuracy: 0.4657\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7340 - val_loss: 11069.8926 - val_accuracy: 0.4657\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7346 - val_loss: 11456.1768 - val_accuracy: 0.4657\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7336 - val_loss: 2973.4636 - val_accuracy: 0.5343\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7362 - val_loss: 4497.0376 - val_accuracy: 0.4657\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.7350\n",
            "Epoch 30: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7350 - val_loss: 16494.4414 - val_accuracy: 0.4657\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7353 - val_loss: 13048.3887 - val_accuracy: 0.4657\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7353 - val_loss: 1356.4298 - val_accuracy: 0.4657\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7362 - val_loss: 17325.0449 - val_accuracy: 0.4657\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7365 - val_loss: 4048.8037 - val_accuracy: 0.4657\n",
            "Epoch 35/100\n",
            "793/804 [============================>.] - ETA: 0s - loss: 0.5409 - accuracy: 0.7341\n",
            "Epoch 35: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7343 - val_loss: 19911.8340 - val_accuracy: 0.4657\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7348 - val_loss: 2951.1462 - val_accuracy: 0.4657\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7359 - val_loss: 12267.1777 - val_accuracy: 0.4657\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7355 - val_loss: 27840.0605 - val_accuracy: 0.4657\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7359 - val_loss: 28294.1133 - val_accuracy: 0.4657\n",
            "Epoch 40/100\n",
            "800/804 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.7363\n",
            "Epoch 40: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7364 - val_loss: 14988.0986 - val_accuracy: 0.4657\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7360 - val_loss: 15046.8271 - val_accuracy: 0.4657\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5402 - accuracy: 0.7358 - val_loss: 35871.0508 - val_accuracy: 0.4657\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7365 - val_loss: 14898.2666 - val_accuracy: 0.4657\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7369 - val_loss: 34916.9727 - val_accuracy: 0.4657\n",
            "Epoch 45/100\n",
            "800/804 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.7370\n",
            "Epoch 45: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7375 - val_loss: 22959.9199 - val_accuracy: 0.4657\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7369 - val_loss: 28684.2168 - val_accuracy: 0.4657\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7363 - val_loss: 45468.1055 - val_accuracy: 0.4657\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7378 - val_loss: 25571.4297 - val_accuracy: 0.4657\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7364 - val_loss: 46317.3906 - val_accuracy: 0.4657\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.7368\n",
            "Epoch 50: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7368 - val_loss: 41862.7227 - val_accuracy: 0.4657\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7371 - val_loss: 43408.1055 - val_accuracy: 0.4657\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7363 - val_loss: 21400.2344 - val_accuracy: 0.4657\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7375 - val_loss: 18385.9570 - val_accuracy: 0.4657\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7373 - val_loss: 29542.7305 - val_accuracy: 0.4657\n",
            "Epoch 55/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7385\n",
            "Epoch 55: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7383 - val_loss: 23447.5410 - val_accuracy: 0.4657\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7376 - val_loss: 25588.0039 - val_accuracy: 0.4657\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7378 - val_loss: 24371.7520 - val_accuracy: 0.4657\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7373 - val_loss: 27993.2188 - val_accuracy: 0.4657\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7377 - val_loss: 47013.7461 - val_accuracy: 0.4657\n",
            "Epoch 60/100\n",
            "787/804 [============================>.] - ETA: 0s - loss: 0.5383 - accuracy: 0.7377\n",
            "Epoch 60: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7372 - val_loss: 45687.1836 - val_accuracy: 0.4657\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7372 - val_loss: 36849.2539 - val_accuracy: 0.4657\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7379 - val_loss: 41235.2148 - val_accuracy: 0.4657\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7375 - val_loss: 32737.6758 - val_accuracy: 0.4657\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7363 - val_loss: 24245.6406 - val_accuracy: 0.4657\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.7376\n",
            "Epoch 65: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7376 - val_loss: 40361.9609 - val_accuracy: 0.4657\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7383 - val_loss: 35567.2539 - val_accuracy: 0.4657\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7376 - val_loss: 25707.4766 - val_accuracy: 0.4657\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7382 - val_loss: 31340.2207 - val_accuracy: 0.4657\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7374 - val_loss: 57272.0820 - val_accuracy: 0.4657\n",
            "Epoch 70/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7388\n",
            "Epoch 70: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7381 - val_loss: 44525.5664 - val_accuracy: 0.4657\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7378 - val_loss: 37305.2617 - val_accuracy: 0.4657\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7383 - val_loss: 41527.6133 - val_accuracy: 0.4657\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7366 - val_loss: 41753.2852 - val_accuracy: 0.4657\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7386 - val_loss: 54921.5234 - val_accuracy: 0.4657\n",
            "Epoch 75/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.7385\n",
            "Epoch 75: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7390 - val_loss: 49081.3711 - val_accuracy: 0.4657\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5377 - accuracy: 0.7387 - val_loss: 34872.5430 - val_accuracy: 0.4657\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7375 - val_loss: 39792.5000 - val_accuracy: 0.4657\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7383 - val_loss: 52823.1875 - val_accuracy: 0.4657\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7389 - val_loss: 58265.2930 - val_accuracy: 0.4657\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7386\n",
            "Epoch 80: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7386 - val_loss: 41266.5391 - val_accuracy: 0.4657\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7379 - val_loss: 36653.1680 - val_accuracy: 0.4657\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7384 - val_loss: 43451.6875 - val_accuracy: 0.4657\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7379 - val_loss: 52998.4648 - val_accuracy: 0.4657\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7384 - val_loss: 52495.2227 - val_accuracy: 0.4657\n",
            "Epoch 85/100\n",
            "802/804 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7371\n",
            "Epoch 85: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7372 - val_loss: 52377.0703 - val_accuracy: 0.4657\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7381 - val_loss: 45740.9961 - val_accuracy: 0.4657\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7368 - val_loss: 55201.1133 - val_accuracy: 0.4657\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7390 - val_loss: 38522.6523 - val_accuracy: 0.4657\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7381 - val_loss: 43053.7773 - val_accuracy: 0.4657\n",
            "Epoch 90/100\n",
            "802/804 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.7377\n",
            "Epoch 90: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7378 - val_loss: 59080.3516 - val_accuracy: 0.4657\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7386 - val_loss: 50783.9375 - val_accuracy: 0.4657\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7391 - val_loss: 53953.9375 - val_accuracy: 0.4657\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7388 - val_loss: 37836.3203 - val_accuracy: 0.4657\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7383 - val_loss: 48669.3945 - val_accuracy: 0.4657\n",
            "Epoch 95/100\n",
            "779/804 [============================>.] - ETA: 0s - loss: 0.5369 - accuracy: 0.7389\n",
            "Epoch 95: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7391 - val_loss: 27260.7461 - val_accuracy: 0.4657\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7381 - val_loss: 59739.8633 - val_accuracy: 0.4657\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7376 - val_loss: 32651.9043 - val_accuracy: 0.4657\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7383 - val_loss: 65662.5469 - val_accuracy: 0.4657\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7383 - val_loss: 44013.0117 - val_accuracy: 0.4657\n",
            "Epoch 100/100\n",
            "775/804 [===========================>..] - ETA: 0s - loss: 0.5359 - accuracy: 0.7385\n",
            "Epoch 100: saving model to model_weights.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7385 - val_loss: 52889.2031 - val_accuracy: 0.4657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed31b5a110>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "g5UsF2zMDQZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1018820-0f5d-4b14-db0d-a5affb88c965"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5543 - accuracy: 0.7280 - 224ms/epoch - 837us/step\n",
            "Loss: 0.5543296933174133, Accuracy: 0.7280466556549072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export our model to HDF5 file\n",
        "# save the model to an HDF5 file\n",
        "model.save('AlphabetSoupCharity.h5')\n"
      ],
      "metadata": {
        "id": "zJE2SDxyDUZ5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing the Model: Trial 2\n"
      ],
      "metadata": {
        "id": "AXxBYoFQz6eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#Sequential = layers are stacked on top of each other in sequence\n",
        "model2 = tf.keras.models.Sequential()\n",
        "\n",
        "#the number of input features - this is the length of the training -pick any column\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "print(number_input_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s1QXT4C112l",
        "outputId": "db491069-7d85-4307-e3e7-c558c7979a6c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hidden nodes for each layer pick a random number\n",
        "units_layer1 = 50\n",
        "units_layer2 = 30\n",
        "\n",
        "#the more layers - \n",
        "# First hidden layer\n",
        "model2.add(Dense(units=units_layer1, \n",
        "                                activation='relu', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "model2.add(Dense(units=units_layer2, \n",
        "                                activation='tanh', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Output layer\n",
        "model2.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXY8DJmh1psa",
        "outputId": "7d6d55c1-f5d1-4b4f-9022-5e7fa205a280"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 50)                2250      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 30)                1530      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,811\n",
            "Trainable params: 3,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model - \n",
        "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "o-n7x57L2M0F"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the checkpoint file path\n",
        "checkpoint_filepath = 'model_weights2.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    period=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "weights = model2.get_weights()\n",
        "for i, layer_weights in enumerate(weights):\n",
        "    print(f'Layer {i} weights:')\n",
        "    print(layer_weights)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model2.fit(X_train_scaled, y_train,epochs=100,\n",
        "          validation_data=(X_test, y_test),\n",
        "    callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Le5LVZ2fez",
        "outputId": "c9ef68c5-503c-42a7-e5e6-ea6ad67b9441"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 weights:\n",
            "[[-0.09638971  0.0664556  -0.0693451  ... -0.06661662 -0.12065934\n",
            "   0.20426849]\n",
            " [-0.07538232  0.15046117 -0.08218205 ...  0.19200003  0.03280437\n",
            "  -0.09176357]\n",
            " [-0.02252659  0.2512479   0.16802925 ...  0.11660525  0.06333047\n",
            "   0.12921938]\n",
            " ...\n",
            " [-0.23540597  0.19408798 -0.07421947 ...  0.24893305  0.15074253\n",
            "  -0.22812459]\n",
            " [ 0.1515007  -0.15676022  0.07582065 ...  0.23942083  0.08367932\n",
            "   0.20930314]\n",
            " [-0.07328697  0.0347845   0.01928809 ... -0.07080226 -0.20972635\n",
            "   0.20275813]]\n",
            "Layer 1 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "Layer 2 weights:\n",
            "[[-0.11612764 -0.02251187 -0.15872951 ...  0.18456894  0.08648512\n",
            "   0.20284867]\n",
            " [-0.10573068 -0.07613347 -0.06582995 ... -0.2118823  -0.05724867\n",
            "  -0.15412977]\n",
            " [ 0.2147888  -0.25020018 -0.17367496 ... -0.0247487   0.11775497\n",
            "  -0.2730487 ]\n",
            " ...\n",
            " [-0.1906782  -0.06678754  0.0563207  ...  0.18010658  0.2703817\n",
            "   0.00680113]\n",
            " [-0.14114757 -0.08046551 -0.22192335 ... -0.00510636  0.01275897\n",
            "  -0.02308038]\n",
            " [-0.04984626  0.16071534  0.25805086 ...  0.00312671 -0.24850151\n",
            "   0.23052299]]\n",
            "Layer 3 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "Layer 4 weights:\n",
            "[[-0.24103022]\n",
            " [-0.26376107]\n",
            " [-0.34654367]\n",
            " [ 0.07686877]\n",
            " [ 0.10292435]\n",
            " [-0.04093611]\n",
            " [ 0.22864741]\n",
            " [-0.36126217]\n",
            " [ 0.41246402]\n",
            " [ 0.33718127]\n",
            " [ 0.42818493]\n",
            " [ 0.3183307 ]\n",
            " [-0.1379092 ]\n",
            " [ 0.43555754]\n",
            " [ 0.3289407 ]\n",
            " [-0.2349064 ]\n",
            " [-0.41864392]\n",
            " [-0.14010769]\n",
            " [-0.19288571]\n",
            " [-0.29645902]\n",
            " [-0.37817046]\n",
            " [-0.2918021 ]\n",
            " [ 0.17070878]\n",
            " [-0.37889925]\n",
            " [-0.19045143]\n",
            " [-0.43184885]\n",
            " [ 0.39163703]\n",
            " [ 0.20370924]\n",
            " [ 0.15694529]\n",
            " [ 0.27237225]]\n",
            "Layer 5 weights:\n",
            "[0.]\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 3s 2ms/step - loss: 0.5720 - accuracy: 0.7181 - val_loss: 0.8944 - val_accuracy: 0.4657\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5552 - accuracy: 0.7276 - val_loss: 0.9194 - val_accuracy: 0.4657\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7281 - val_loss: 0.9226 - val_accuracy: 0.4657\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7280 - val_loss: 0.9462 - val_accuracy: 0.4657\n",
            "Epoch 5/100\n",
            "776/804 [===========================>..] - ETA: 0s - loss: 0.5482 - accuracy: 0.7304\n",
            "Epoch 5: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7305 - val_loss: 0.8088 - val_accuracy: 0.4657\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7300 - val_loss: 0.7007 - val_accuracy: 0.4657\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7309 - val_loss: 0.9213 - val_accuracy: 0.4657\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7302 - val_loss: 0.8032 - val_accuracy: 0.4657\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7315 - val_loss: 0.8021 - val_accuracy: 0.4657\n",
            "Epoch 10/100\n",
            "786/804 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.7324\n",
            "Epoch 10: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7315 - val_loss: 0.8139 - val_accuracy: 0.4657\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7322 - val_loss: 0.8063 - val_accuracy: 0.4657\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7311 - val_loss: 0.8547 - val_accuracy: 0.4657\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7316 - val_loss: 0.8039 - val_accuracy: 0.4657\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7337 - val_loss: 0.8253 - val_accuracy: 0.4657\n",
            "Epoch 15/100\n",
            "773/804 [===========================>..] - ETA: 0s - loss: 0.5429 - accuracy: 0.7328\n",
            "Epoch 15: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7325 - val_loss: 0.8529 - val_accuracy: 0.4657\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7313 - val_loss: 0.8122 - val_accuracy: 0.4657\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7336 - val_loss: 0.8306 - val_accuracy: 0.4657\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7346 - val_loss: 0.8375 - val_accuracy: 0.4657\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7340 - val_loss: 0.9426 - val_accuracy: 0.4657\n",
            "Epoch 20/100\n",
            "781/804 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.7344\n",
            "Epoch 20: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7346 - val_loss: 0.7757 - val_accuracy: 0.4657\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5411 - accuracy: 0.7341 - val_loss: 0.6958 - val_accuracy: 0.5343\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7357 - val_loss: 0.7139 - val_accuracy: 0.4657\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7351 - val_loss: 0.7684 - val_accuracy: 0.4657\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7339 - val_loss: 0.8243 - val_accuracy: 0.4657\n",
            "Epoch 25/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5411 - accuracy: 0.7347\n",
            "Epoch 25: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7348 - val_loss: 0.7084 - val_accuracy: 0.4657\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7348 - val_loss: 0.6998 - val_accuracy: 0.4657\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7352 - val_loss: 0.6993 - val_accuracy: 0.4657\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7337 - val_loss: 0.7073 - val_accuracy: 0.4657\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7354 - val_loss: 0.7069 - val_accuracy: 0.4657\n",
            "Epoch 30/100\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.7356\n",
            "Epoch 30: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7358 - val_loss: 0.9005 - val_accuracy: 0.4657\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7364 - val_loss: 0.9416 - val_accuracy: 0.4657\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7363 - val_loss: 0.8934 - val_accuracy: 0.4657\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7354 - val_loss: 0.7358 - val_accuracy: 0.4657\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7368 - val_loss: 0.7013 - val_accuracy: 0.5343\n",
            "Epoch 35/100\n",
            "791/804 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7359\n",
            "Epoch 35: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7362 - val_loss: 0.8123 - val_accuracy: 0.4657\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7356 - val_loss: 0.7271 - val_accuracy: 0.5343\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7369 - val_loss: 0.6944 - val_accuracy: 0.5343\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7372 - val_loss: 0.6917 - val_accuracy: 0.5343\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7359 - val_loss: 0.6925 - val_accuracy: 0.5343\n",
            "Epoch 40/100\n",
            "792/804 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7364\n",
            "Epoch 40: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7368 - val_loss: 0.7295 - val_accuracy: 0.4657\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7370 - val_loss: 0.7527 - val_accuracy: 0.4657\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7363 - val_loss: 0.6908 - val_accuracy: 0.5343\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7356 - val_loss: 0.7546 - val_accuracy: 0.5343\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7373 - val_loss: 0.6921 - val_accuracy: 0.5343\n",
            "Epoch 45/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.7359\n",
            "Epoch 45: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7358 - val_loss: 0.6954 - val_accuracy: 0.4657\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7388 - val_loss: 0.6915 - val_accuracy: 0.5343\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7372 - val_loss: 0.8722 - val_accuracy: 0.5343\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7365 - val_loss: 0.7445 - val_accuracy: 0.5343\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7377 - val_loss: 0.6921 - val_accuracy: 0.5343\n",
            "Epoch 50/100\n",
            "793/804 [============================>.] - ETA: 0s - loss: 0.5363 - accuracy: 0.7380\n",
            "Epoch 50: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7378 - val_loss: 0.8369 - val_accuracy: 0.4657\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7372 - val_loss: 0.7232 - val_accuracy: 0.5343\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7375 - val_loss: 0.6922 - val_accuracy: 0.5343\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7386 - val_loss: 0.9539 - val_accuracy: 0.5343\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7379 - val_loss: 0.9311 - val_accuracy: 0.5343\n",
            "Epoch 55/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5365 - accuracy: 0.7381\n",
            "Epoch 55: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5366 - accuracy: 0.7380 - val_loss: 0.6914 - val_accuracy: 0.5343\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7377 - val_loss: 0.6909 - val_accuracy: 0.5343\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7378 - val_loss: 0.9397 - val_accuracy: 0.5343\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7379 - val_loss: 0.7068 - val_accuracy: 0.5343\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7391 - val_loss: 0.7098 - val_accuracy: 0.4657\n",
            "Epoch 60/100\n",
            "780/804 [============================>.] - ETA: 0s - loss: 0.5349 - accuracy: 0.7395\n",
            "Epoch 60: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7391 - val_loss: 0.7615 - val_accuracy: 0.5343\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7391 - val_loss: 0.8039 - val_accuracy: 0.5343\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7392 - val_loss: 1.0186 - val_accuracy: 0.5343\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7381 - val_loss: 0.7291 - val_accuracy: 0.5343\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7379 - val_loss: 0.7255 - val_accuracy: 0.5343\n",
            "Epoch 65/100\n",
            "770/804 [===========================>..] - ETA: 0s - loss: 0.5361 - accuracy: 0.7380\n",
            "Epoch 65: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7382 - val_loss: 0.7379 - val_accuracy: 0.5343\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7390 - val_loss: 0.6951 - val_accuracy: 0.5343\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7386 - val_loss: 0.7399 - val_accuracy: 0.5343\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7395 - val_loss: 0.7532 - val_accuracy: 0.5343\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7386 - val_loss: 0.6973 - val_accuracy: 0.5343\n",
            "Epoch 70/100\n",
            "783/804 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.7397\n",
            "Epoch 70: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7392 - val_loss: 0.9423 - val_accuracy: 0.5343\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7388 - val_loss: 0.8290 - val_accuracy: 0.5343\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7394 - val_loss: 1.1851 - val_accuracy: 0.5343\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7395 - val_loss: 0.8119 - val_accuracy: 0.5343\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7393 - val_loss: 0.8282 - val_accuracy: 0.5343\n",
            "Epoch 75/100\n",
            "769/804 [===========================>..] - ETA: 0s - loss: 0.5359 - accuracy: 0.7380\n",
            "Epoch 75: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7388 - val_loss: 0.8003 - val_accuracy: 0.5343\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7398 - val_loss: 0.6954 - val_accuracy: 0.4657\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7393 - val_loss: 0.6909 - val_accuracy: 0.5343\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7392 - val_loss: 0.6870 - val_accuracy: 0.5590\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7398 - val_loss: 0.7483 - val_accuracy: 0.5343\n",
            "Epoch 80/100\n",
            "800/804 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.7396\n",
            "Epoch 80: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7395 - val_loss: 0.6929 - val_accuracy: 0.5343\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7395 - val_loss: 0.6912 - val_accuracy: 0.5343\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7392 - val_loss: 0.8376 - val_accuracy: 0.5343\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7385 - val_loss: 0.8371 - val_accuracy: 0.5343\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7394 - val_loss: 0.7002 - val_accuracy: 0.4657\n",
            "Epoch 85/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5338 - accuracy: 0.7399\n",
            "Epoch 85: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5344 - accuracy: 0.7393 - val_loss: 0.8127 - val_accuracy: 0.5343\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7393 - val_loss: 0.7248 - val_accuracy: 0.5343\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7396 - val_loss: 0.8404 - val_accuracy: 0.5343\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7400 - val_loss: 0.6946 - val_accuracy: 0.4657\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7407 - val_loss: 0.7010 - val_accuracy: 0.4657\n",
            "Epoch 90/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5336 - accuracy: 0.7409\n",
            "Epoch 90: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7407 - val_loss: 0.8342 - val_accuracy: 0.4657\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7407 - val_loss: 0.6976 - val_accuracy: 0.5343\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7400 - val_loss: 0.6923 - val_accuracy: 0.5343\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7395 - val_loss: 0.7047 - val_accuracy: 0.5343\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7407 - val_loss: 0.7918 - val_accuracy: 0.5343\n",
            "Epoch 95/100\n",
            "793/804 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.7390\n",
            "Epoch 95: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7392 - val_loss: 0.7165 - val_accuracy: 0.5343\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7382 - val_loss: 0.8537 - val_accuracy: 0.5343\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7396 - val_loss: 0.7245 - val_accuracy: 0.5343\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7383 - val_loss: 0.7138 - val_accuracy: 0.5343\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7395 - val_loss: 0.7351 - val_accuracy: 0.5343\n",
            "Epoch 100/100\n",
            "796/804 [============================>.] - ETA: 0s - loss: 0.5333 - accuracy: 0.7390\n",
            "Epoch 100: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7386 - val_loss: 0.7381 - val_accuracy: 0.5343\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed22bc95a0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = model2.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_fVJGrl1vVx",
        "outputId": "ab89d1cb-4fd3-4565-d0b0-a867abf8625b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5567 - accuracy: 0.7248 - 251ms/epoch - 936us/step\n",
            "Loss: 0.5567113757133484, Accuracy: 0.724781334400177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Export our model to HDF5 file\n",
        "# save the model to an HDF5 file\n",
        "model.save('AlphabetSoupCharity2.h5')"
      ],
      "metadata": {
        "id": "V-tJgbop1_5G"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model3"
      ],
      "metadata": {
        "id": "ZFCtX1Jj489e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import and read the charity_data.csv.\n",
        "application_df2 = application_df.copy()\n"
      ],
      "metadata": {
        "id": "JQmWoZph_LVf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df2.drop(['STATUS'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "#Split our preproesssed data into our features and target arrays\n",
        "X = application_df2.drop('IS_SUCCESSFUL', axis=1).values # remove the target column\n",
        "y = application_df2['IS_SUCCESSFUL'].values # set the target column as the target variable\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "vW12Q1PZ9xmK",
        "outputId": "ff8fdca2-8983-4fde-82c9-c68982042f78"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a8e87953b655>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mapplication_df2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STATUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Split our preproesssed data into our features and target arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5397\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5398\u001b[0m         \"\"\"\n\u001b[0;32m-> 5399\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5400\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5401\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6934\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6935\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6936\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['STATUS'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4nAjSWf-ybO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#Sequential = layers are stacked on top of each other in sequence\n",
        "model3 = tf.keras.models.Sequential()\n",
        "\n",
        "#the number of input features - this is the length of the training -pick any column\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "print(number_input_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhrN4u633mqD",
        "outputId": "78a702fe-5845-4b7a-e8d8-da034fa7518a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hidden nodes for each layer pick a random number\n",
        "units_layer1 = 30\n",
        "units_layer2 = 20\n",
        "units_layer3 = 10\n",
        "\n",
        "#the more layers - \n",
        "# First hidden layer\n",
        "model3.add(Dense(units=units_layer1, \n",
        "                                activation='relu', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "model3.add(Dense(units=units_layer2, \n",
        "                                activation='tanh', \n",
        "                                input_dim=number_input_features))\n",
        "# Third hidden layer\n",
        "model3.add(Dense(units=units_layer3, \n",
        "                                activation='tanh', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Output layer\n",
        "model3.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nRwIG5Q3pv-",
        "outputId": "c2d1ff53-1aeb-4e66-f6cf-31cfe1213f1a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 30)                1350      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,191\n",
            "Trainable params: 2,191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model - \n",
        "model3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "-fk-7iWa3sb4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the checkpoint file path\n",
        "checkpoint_filepath = 'model_weights2.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    period=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "weights = model3.get_weights()\n",
        "for i, layer_weights in enumerate(weights):\n",
        "    print(f'Layer {i} weights:')\n",
        "    print(layer_weights)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model3.fit(X_train_scaled, y_train,epochs=50,\n",
        "          validation_data=(X_test, y_test),\n",
        "    callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-5RLkZq4GDm",
        "outputId": "158b9efc-cf0a-4cd5-e411-e4fa039f44b3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 weights:\n",
            "[[ 0.24951968 -0.06057891 -0.02224922 ... -0.09999511 -0.15307193\n",
            "  -0.06375477]\n",
            " [-0.1307388   0.11063507  0.15409079 ... -0.20852527 -0.19661069\n",
            "  -0.13380508]\n",
            " [-0.0877105   0.03928646  0.253315   ... -0.04846716  0.25391087\n",
            "  -0.10587707]\n",
            " ...\n",
            " [-0.1459414   0.18996319 -0.09153096 ... -0.06556448 -0.16311218\n",
            "   0.10143259]\n",
            " [ 0.19011545  0.18695244 -0.15700419 ...  0.23566958  0.01670289\n",
            "   0.12534901]\n",
            " [ 0.0336799   0.09189811  0.09694973 ... -0.13403386 -0.14397283\n",
            "  -0.0638811 ]]\n",
            "Layer 1 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "Layer 2 weights:\n",
            "[[-0.30834827 -0.03932238 -0.22485931  0.1465463  -0.10598011  0.22486669\n",
            "   0.19228029  0.02254534 -0.08201206  0.17646366  0.25701457  0.20493042\n",
            "   0.329894   -0.28321883 -0.31782925  0.10279351  0.05490732  0.3417529\n",
            "  -0.31361836 -0.02238643]\n",
            " [-0.18819033  0.23425078 -0.03612936 -0.25031507  0.2439056   0.2147817\n",
            "   0.04804048  0.21064442  0.01490563  0.21443975  0.21372032  0.22317898\n",
            "   0.07917541  0.21887338  0.14815387  0.02224156  0.20676726  0.14516416\n",
            "   0.20749044 -0.0406189 ]\n",
            " [ 0.24686533 -0.3174628   0.03920057 -0.3024488  -0.05336955 -0.1838434\n",
            "   0.06789008  0.23789304 -0.31076536 -0.31933942 -0.28434744  0.01837376\n",
            "  -0.16985239  0.24265456 -0.10812391  0.30362278 -0.17095077 -0.08793232\n",
            "   0.25186718 -0.20310958]\n",
            " [-0.25606215  0.08777168  0.16085827 -0.11895378 -0.02301511  0.2689463\n",
            "  -0.11734203 -0.03423077  0.0200673  -0.12528262  0.2434426  -0.01537293\n",
            "  -0.29487443 -0.25683594 -0.21043883 -0.34387025 -0.06668836  0.15713155\n",
            "   0.04662538  0.323354  ]\n",
            " [ 0.19767171 -0.14017361  0.27210337 -0.08240801 -0.2302249   0.04965174\n",
            "  -0.1517634   0.08207014 -0.21087433 -0.0593327   0.16641045  0.26233965\n",
            "  -0.25796047  0.33645165  0.06583661 -0.01834428  0.2093218  -0.17637599\n",
            "  -0.2062794  -0.05498901]\n",
            " [ 0.14505365 -0.28449824  0.11869577  0.28405893 -0.15983424  0.2939852\n",
            "  -0.08300298 -0.17739548 -0.1754408   0.32934362 -0.21285857  0.08876708\n",
            "  -0.00681561  0.13532728  0.3020674   0.088276   -0.26675326 -0.15679713\n",
            "   0.25850803 -0.24330354]\n",
            " [-0.05028984  0.08113387 -0.26820278  0.00855505  0.10459572 -0.04313749\n",
            "   0.0417698   0.10688043 -0.06045395 -0.06055808  0.03694949 -0.16665837\n",
            "   0.0728184   0.27475035 -0.0937244  -0.01101419  0.08061868  0.05661595\n",
            "  -0.16822131 -0.14805871]\n",
            " [ 0.04038036 -0.014734    0.12485281  0.12416887  0.3180558  -0.09312654\n",
            "   0.11194232 -0.03573918 -0.07256436  0.06013843  0.33164865  0.03259256\n",
            "  -0.24445517 -0.06579044 -0.20754667 -0.1223831  -0.1280509   0.29119545\n",
            "   0.20742106  0.01350176]\n",
            " [ 0.34489387 -0.10550736  0.06347725 -0.10037328 -0.29572174  0.15790129\n",
            "  -0.15437631  0.01484978  0.15533525  0.2932005  -0.34521285  0.1709612\n",
            "   0.29694152  0.11239493 -0.12920642  0.24031287 -0.3173001  -0.26517057\n",
            "   0.07148325 -0.30698735]\n",
            " [-0.17370194  0.01471624  0.11944899 -0.02373159 -0.10018787 -0.27344903\n",
            "   0.21162409 -0.3264436  -0.30223954  0.12327525  0.32513928  0.00756118\n",
            "   0.16709232  0.2842672   0.34269595  0.183972   -0.17160174  0.23472834\n",
            "   0.34298563  0.10449249]\n",
            " [ 0.05939966  0.05274805  0.2892477  -0.06665477  0.18076706 -0.2763881\n",
            "   0.07371518  0.15126058 -0.12363815  0.25632668  0.01607972 -0.0533323\n",
            "   0.30111974 -0.06987745  0.18980646  0.15200266 -0.27132916 -0.14842781\n",
            "  -0.22862405 -0.04060435]\n",
            " [ 0.06413195 -0.12091622 -0.3337335  -0.18409242  0.03978035 -0.26420432\n",
            "   0.2270189   0.19930518  0.16881627 -0.20947607  0.29312855 -0.22746834\n",
            "  -0.12809911  0.21666592 -0.28138128 -0.11065325  0.24908036 -0.14588964\n",
            "  -0.17115064 -0.28685975]\n",
            " [-0.32112074 -0.27225304  0.17582244  0.20915943 -0.04480928  0.29111284\n",
            "   0.06377754 -0.3135381  -0.00600433 -0.30875322  0.31043303  0.2992316\n",
            "  -0.12157801 -0.05726397 -0.17899963 -0.24416743  0.05800927 -0.2740023\n",
            "  -0.06970665 -0.1666862 ]\n",
            " [-0.18031497 -0.07607043  0.2801078   0.22912341  0.0943853  -0.13618688\n",
            "   0.00868142 -0.13381778  0.02346638 -0.19599117  0.07672107  0.03540388\n",
            "   0.28345454 -0.18667346 -0.00212571 -0.22555456  0.24610543 -0.1126432\n",
            "  -0.00539407 -0.13833697]\n",
            " [-0.07997125 -0.04282895  0.24412394  0.15880913 -0.12374999 -0.08037734\n",
            "  -0.01233715  0.02648765  0.32294428 -0.20604195 -0.11299841  0.02885839\n",
            "  -0.04908723 -0.14768837  0.12739843 -0.05312386 -0.23078395  0.14535668\n",
            "  -0.11161345  0.19760203]\n",
            " [-0.3295422  -0.08369139 -0.03623417 -0.2894536  -0.0792248   0.08883497\n",
            "   0.08163363  0.330881    0.16894656 -0.27002126  0.18359375 -0.0367212\n",
            "  -0.0362244   0.06568134  0.03874162 -0.1380911   0.17507285  0.301987\n",
            "  -0.0330655  -0.0347504 ]\n",
            " [ 0.04123816  0.22719908  0.08024338  0.02614719 -0.24195549 -0.00543091\n",
            "  -0.27539644 -0.06306669  0.24032152 -0.18230227 -0.18433812 -0.21106859\n",
            "   0.24999678  0.00543883  0.12201384  0.21533346 -0.3136486   0.24311137\n",
            "  -0.11264418 -0.01100901]\n",
            " [ 0.07626981 -0.23369238 -0.18579255 -0.32716256 -0.16716382 -0.01495203\n",
            "  -0.07877633  0.06399566  0.07217091 -0.14018527  0.13884431  0.24366713\n",
            "   0.09430197  0.03991562  0.2781812  -0.04355508 -0.06568012 -0.13928503\n",
            "  -0.33473736 -0.00284377]\n",
            " [-0.22608198 -0.2184981   0.01539993 -0.04477692 -0.22309071  0.19415212\n",
            "   0.01817045 -0.02793893  0.23646104  0.0559155  -0.03167665  0.31620264\n",
            "   0.16626531  0.10454395  0.23290288  0.11907956  0.2889796   0.29805946\n",
            "   0.26062    -0.05662405]\n",
            " [-0.34365907 -0.28848895  0.13679576 -0.2990559  -0.07601848  0.18392396\n",
            "   0.23715228 -0.31430635  0.16662121  0.18672878 -0.09104839 -0.32952747\n",
            "   0.00112531 -0.09891069  0.26532543 -0.21624784 -0.34198403  0.33315295\n",
            "   0.170528   -0.18724523]\n",
            " [ 0.25653684 -0.26018256 -0.05980495 -0.00744373 -0.09095541 -0.21192117\n",
            "  -0.05416861 -0.09450531  0.1383003   0.29406422  0.23990226 -0.171417\n",
            "   0.03861666  0.02048892 -0.15591803  0.2995863   0.13851893 -0.01008323\n",
            "  -0.32995397 -0.15054634]\n",
            " [-0.279828    0.1607011   0.22709197 -0.21881558  0.03470778 -0.27423587\n",
            "   0.24203014 -0.05760917 -0.10970305  0.17072177 -0.30314863  0.32752538\n",
            "  -0.09976815 -0.20117787  0.22843713  0.29750472  0.30046493 -0.21172154\n",
            "  -0.1211886  -0.1811584 ]\n",
            " [ 0.2552222   0.22579509 -0.04096925 -0.12361321 -0.07914245  0.22044611\n",
            "  -0.0483644   0.2677421   0.15544832 -0.25744528 -0.16477539  0.09979662\n",
            "  -0.2597877  -0.23840302 -0.301381   -0.24677135  0.11977994  0.32050872\n",
            "  -0.17891069  0.23866343]\n",
            " [-0.00990269 -0.33452463  0.03484944 -0.03318879  0.05502006  0.08043179\n",
            "   0.0184297   0.10275728 -0.00205675 -0.3247477  -0.27008122  0.02243087\n",
            "   0.29754937 -0.03485703  0.02368516  0.06899124  0.03262767 -0.34344324\n",
            "   0.07484567 -0.12688355]\n",
            " [-0.0826205   0.16837913 -0.3278323  -0.34248304  0.22277826  0.15900856\n",
            "   0.07110208 -0.10310315 -0.19741404 -0.2804162  -0.14320487 -0.05469769\n",
            "   0.3203892   0.05330548  0.05233297  0.06209806 -0.1051946  -0.22905847\n",
            "  -0.11658533 -0.31405115]\n",
            " [ 0.31876814  0.34137303  0.20520324 -0.28443497  0.08406776 -0.2399108\n",
            "   0.16764319 -0.02956322  0.16535097 -0.20680475 -0.32699475 -0.23518917\n",
            "  -0.2480976   0.04888141  0.11936507  0.3038621  -0.0532077  -0.33777612\n",
            "  -0.11558829 -0.10020621]\n",
            " [-0.29515955  0.11407128 -0.1006019  -0.22517085  0.27672207 -0.13547777\n",
            "  -0.29301548 -0.32106245 -0.26225594  0.1327512   0.3435344   0.02523258\n",
            "   0.0156354  -0.01163107 -0.07207277  0.03637108  0.25426322 -0.1514754\n",
            "  -0.14386947  0.26135188]\n",
            " [-0.12694971 -0.3441594  -0.25329313 -0.11483432  0.34486812  0.3368113\n",
            "  -0.14026488  0.24633038  0.05497843  0.33979034 -0.15674716 -0.08860421\n",
            "  -0.09240586 -0.27806923 -0.22023639 -0.10369384 -0.12488453 -0.32383502\n",
            "  -0.32854185 -0.14399658]\n",
            " [-0.09134218  0.33135945  0.22297418  0.0793885   0.00580844  0.11820123\n",
            "   0.25935924 -0.3394699   0.04623976 -0.06914487  0.10883248 -0.26718825\n",
            "  -0.12748127  0.03096893 -0.13960424 -0.05412245  0.26715857 -0.2707042\n",
            "   0.26071787  0.3158599 ]\n",
            " [-0.27059245 -0.01219746  0.30580407  0.24548036 -0.17393592  0.029544\n",
            "  -0.14787437 -0.00887281 -0.32217214 -0.30630028  0.11797914  0.30194747\n",
            "  -0.1154075   0.21942604 -0.24963105 -0.28391325 -0.20103382 -0.14509627\n",
            "  -0.17914103 -0.07589978]]\n",
            "Layer 3 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 4 weights:\n",
            "[[ 0.20986658 -0.14906871  0.23946798 -0.35561758  0.38859147  0.17882788\n",
            "  -0.33406118 -0.33446646 -0.06077293  0.33152777]\n",
            " [-0.36328554 -0.041125   -0.44137272  0.07332414 -0.3396513   0.431333\n",
            "   0.1887582  -0.2605889  -0.01127273 -0.29880926]\n",
            " [-0.26853412  0.3643564   0.08004659  0.3910774   0.10345536  0.38019198\n",
            "  -0.03463542 -0.40435946 -0.06726024 -0.07738516]\n",
            " [-0.254868    0.24459648  0.33086628  0.1540103  -0.14884213 -0.24658288\n",
            "  -0.07329196 -0.24419035 -0.39462703 -0.32787624]\n",
            " [-0.36655593  0.00147951  0.19745618  0.2713819   0.33026463  0.14607608\n",
            "  -0.21757507 -0.35206017  0.18060243  0.13208294]\n",
            " [-0.35628387 -0.25603104 -0.03455204  0.03286791  0.3598112  -0.2595101\n",
            "  -0.41937256 -0.32367247  0.18510175  0.03722373]\n",
            " [ 0.22224885 -0.04030484 -0.3172115   0.3377812  -0.42726606  0.4350611\n",
            "  -0.36544502  0.29018915 -0.26836193  0.42123765]\n",
            " [-0.1931797  -0.09401307 -0.23415223 -0.00388378 -0.3983302   0.19752783\n",
            "   0.41281712  0.2548728  -0.14500314 -0.3682437 ]\n",
            " [ 0.14533812  0.3817202  -0.2749548   0.15181905 -0.02082166  0.12938792\n",
            "   0.36552787  0.32287443 -0.06682575 -0.31703663]\n",
            " [ 0.2057398   0.3225994  -0.00541854  0.18196392  0.10337394 -0.34911084\n",
            "   0.05561209  0.34840786 -0.20311333  0.26383936]\n",
            " [-0.3148778   0.20575625  0.1441558  -0.22505273 -0.23100224 -0.4323664\n",
            "  -0.01559845 -0.00403666 -0.34585422  0.39978927]\n",
            " [ 0.14997649 -0.19731416  0.3327741  -0.17031601 -0.13857508  0.0471437\n",
            "  -0.29601508  0.22870845 -0.12626919  0.13975704]\n",
            " [ 0.11045426 -0.34366706 -0.3711318  -0.38943946  0.39815181  0.4387632\n",
            "  -0.17303842  0.41531724  0.2903043   0.04492506]\n",
            " [-0.22456673  0.32341468  0.13459504  0.3668741   0.3959539   0.24570078\n",
            "   0.16244042  0.06890953 -0.36003417  0.18207407]\n",
            " [ 0.36443913 -0.064877    0.39914066  0.2935999   0.06489033  0.18734676\n",
            "  -0.34753877 -0.3934481   0.20956677 -0.23564401]\n",
            " [ 0.22079843 -0.02184418  0.35841924  0.05508804  0.3128925   0.1705671\n",
            "  -0.14400235 -0.23857607  0.10217291  0.3532772 ]\n",
            " [ 0.3449943  -0.10911733 -0.38973397  0.05892622  0.14839476 -0.41524556\n",
            "  -0.23877983  0.30889153  0.22254843  0.11536229]\n",
            " [ 0.15800804 -0.4360315   0.43415862  0.20081162  0.30102897  0.16963017\n",
            "  -0.01912835  0.23855633  0.14270401 -0.10942239]\n",
            " [-0.06760615 -0.19896896 -0.36512834 -0.33464217  0.43138218 -0.3716726\n",
            "   0.04702237  0.06866461 -0.4090343   0.3570552 ]\n",
            " [ 0.26837927 -0.3100664   0.08446711  0.27854812  0.4416008   0.39213097\n",
            "   0.0284315   0.36138475  0.24469638 -0.18093479]]\n",
            "Layer 5 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 6 weights:\n",
            "[[ 0.47937363]\n",
            " [-0.24371687]\n",
            " [-0.33288112]\n",
            " [ 0.19724464]\n",
            " [-0.4969139 ]\n",
            " [ 0.00135601]\n",
            " [-0.46857762]\n",
            " [ 0.3055753 ]\n",
            " [ 0.61310214]\n",
            " [-0.20150149]]\n",
            "Layer 7 weights:\n",
            "[0.]\n",
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.7168 - val_loss: 0.8165 - val_accuracy: 0.4657\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5560 - accuracy: 0.7293 - val_loss: 0.7808 - val_accuracy: 0.4657\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5527 - accuracy: 0.7306 - val_loss: 0.8476 - val_accuracy: 0.4657\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7301 - val_loss: 0.7392 - val_accuracy: 0.4657\n",
            "Epoch 5/50\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5509 - accuracy: 0.7300\n",
            "Epoch 5: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5503 - accuracy: 0.7303 - val_loss: 0.9060 - val_accuracy: 0.4657\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7297 - val_loss: 0.8966 - val_accuracy: 0.4657\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7311 - val_loss: 0.9196 - val_accuracy: 0.4657\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7320 - val_loss: 0.8717 - val_accuracy: 0.4657\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7322 - val_loss: 0.9172 - val_accuracy: 0.4657\n",
            "Epoch 10/50\n",
            "778/804 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.7321\n",
            "Epoch 10: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7323 - val_loss: 0.7043 - val_accuracy: 0.4657\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7323 - val_loss: 0.8875 - val_accuracy: 0.4657\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7326 - val_loss: 0.8801 - val_accuracy: 0.4657\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5448 - accuracy: 0.7328 - val_loss: 0.7188 - val_accuracy: 0.4657\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7332 - val_loss: 0.7225 - val_accuracy: 0.4657\n",
            "Epoch 15/50\n",
            "795/804 [============================>.] - ETA: 0s - loss: 0.5443 - accuracy: 0.7332\n",
            "Epoch 15: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5447 - accuracy: 0.7327 - val_loss: 0.9458 - val_accuracy: 0.4657\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7329 - val_loss: 1.1857 - val_accuracy: 0.4657\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7332 - val_loss: 0.9055 - val_accuracy: 0.4657\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7350 - val_loss: 0.9292 - val_accuracy: 0.4657\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7343 - val_loss: 0.9607 - val_accuracy: 0.4657\n",
            "Epoch 20/50\n",
            "796/804 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.7359\n",
            "Epoch 20: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7358 - val_loss: 0.9389 - val_accuracy: 0.4657\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5420 - accuracy: 0.7329 - val_loss: 0.9911 - val_accuracy: 0.4657\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7346 - val_loss: 0.9144 - val_accuracy: 0.4657\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7353 - val_loss: 0.9541 - val_accuracy: 0.4657\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5413 - accuracy: 0.7362 - val_loss: 0.9541 - val_accuracy: 0.4657\n",
            "Epoch 25/50\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.7365\n",
            "Epoch 25: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7365 - val_loss: 0.9912 - val_accuracy: 0.4657\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7366 - val_loss: 1.3892 - val_accuracy: 0.4657\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7350 - val_loss: 0.9604 - val_accuracy: 0.4657\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7363 - val_loss: 1.3749 - val_accuracy: 0.4657\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7356 - val_loss: 1.1482 - val_accuracy: 0.4657\n",
            "Epoch 30/50\n",
            "792/804 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7382\n",
            "Epoch 30: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7376 - val_loss: 1.1570 - val_accuracy: 0.4657\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7374 - val_loss: 1.1696 - val_accuracy: 0.4657\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7364 - val_loss: 1.0721 - val_accuracy: 0.4657\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7364 - val_loss: 1.3878 - val_accuracy: 0.4657\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7370 - val_loss: 1.0452 - val_accuracy: 0.4657\n",
            "Epoch 35/50\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7386\n",
            "Epoch 35: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7386 - val_loss: 1.2199 - val_accuracy: 0.4657\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7372 - val_loss: 0.9920 - val_accuracy: 0.4657\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7370 - val_loss: 1.2342 - val_accuracy: 0.4657\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7376 - val_loss: 1.5652 - val_accuracy: 0.4657\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7382 - val_loss: 1.5206 - val_accuracy: 0.4657\n",
            "Epoch 40/50\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.7366\n",
            "Epoch 40: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7364 - val_loss: 0.9766 - val_accuracy: 0.4657\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7382 - val_loss: 0.9591 - val_accuracy: 0.4657\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7383 - val_loss: 0.9661 - val_accuracy: 0.4657\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7379 - val_loss: 1.2948 - val_accuracy: 0.4657\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7385 - val_loss: 0.9536 - val_accuracy: 0.4657\n",
            "Epoch 45/50\n",
            "788/804 [============================>.] - ETA: 0s - loss: 0.5370 - accuracy: 0.7385\n",
            "Epoch 45: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7379 - val_loss: 1.5702 - val_accuracy: 0.4657\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7389 - val_loss: 0.9909 - val_accuracy: 0.4657\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7382 - val_loss: 0.7244 - val_accuracy: 0.4657\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7389 - val_loss: 0.9595 - val_accuracy: 0.4657\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7382 - val_loss: 0.7368 - val_accuracy: 0.4657\n",
            "Epoch 50/50\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5369 - accuracy: 0.7377\n",
            "Epoch 50: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7378 - val_loss: 0.9953 - val_accuracy: 0.4657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed32301ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = model3.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTPzaon46ojd",
        "outputId": "58407875-919c-4539-dc1d-2573650179fd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5522 - accuracy: 0.7304 - 273ms/epoch - 1ms/step\n",
            "Loss: 0.5522164106369019, Accuracy: 0.7303789854049683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Export our model to HDF5 file\n",
        "# save the model to an HDF5 file\n",
        "model.save('AlphabetSoupCharity3.h5')\n",
        "     "
      ],
      "metadata": {
        "id": "Uxt-wplQ6tZj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending on the model how much error can I tolerate-- look at the confusion matrix."
      ],
      "metadata": {
        "id": "dLrmgj2A6VG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "iyYWNSu4Aluk",
        "outputId": "5df83f0c-b75e-4d4d-a8f0-87bdc1062d4c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                     0.0   \n",
              "1       1   108590              1                     0.0   \n",
              "2       1     5000              0                     0.0   \n",
              "3       1     6692              1                     0.0   \n",
              "4       1   142590              1                     0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                   1.0                   0.0                  0.0   \n",
              "1                   0.0                   0.0                  1.0   \n",
              "2                   0.0                   0.0                  0.0   \n",
              "3                   0.0                   0.0                  1.0   \n",
              "4                   0.0                   0.0                  1.0   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                  0.0                  0.0                  0.0  ...   \n",
              "1                  0.0                  0.0                  0.0  ...   \n",
              "2                  0.0                  1.0                  0.0  ...   \n",
              "3                  0.0                  0.0                  0.0  ...   \n",
              "4                  0.0                  0.0                  0.0  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                0.0                     0.0                       0.0   \n",
              "1                1.0                     0.0                       0.0   \n",
              "2                0.0                     0.0                       0.0   \n",
              "3                0.0                     1.0                       0.0   \n",
              "4                0.0                     0.0                       1.0   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                 0.0               0.0                     0.0   \n",
              "1                 0.0               0.0                     0.0   \n",
              "2                 0.0               0.0                     0.0   \n",
              "3                 0.0               0.0                     0.0   \n",
              "4                 0.0               0.0                     0.0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0              0.0                0.0                       1.0   \n",
              "1              0.0                0.0                       1.0   \n",
              "2              0.0                0.0                       1.0   \n",
              "3              0.0                0.0                       1.0   \n",
              "4              0.0                0.0                       1.0   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                       0.0  \n",
              "1                       0.0  \n",
              "2                       0.0  \n",
              "3                       0.0  \n",
              "4                       0.0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-585aca03-e54b-4894-8c0f-052880c45c0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-585aca03-e54b-4894-8c0f-052880c45c0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-585aca03-e54b-4894-8c0f-052880c45c0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-585aca03-e54b-4894-8c0f-052880c45c0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of the model is 0.7266, which means it correctly predicts the outcome for 72.66% of the cases in the test set. While this is not a bad accuracy, whether this model is considered \"good\" or not depends on the specific context and requirements of the project.\n",
        "\n",
        "For example, if the consequences of a false positive (predicting a success when it will actually fail) or a false negative (predicting a failure when it will actually succeed) are very different, then the accuracy alone may not be a sufficient metric to evaluate the model's performance.\n",
        "\n",
        "It's important to also consider other metrics such as precision, recall, F1-score, and the confusion matrix to get a better understanding of the model's performance. Additionally, if the project requirements demand a higher accuracy, then further optimization may be necessary."
      ],
      "metadata": {
        "id": "4r3GdJHQD7MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#look at the confusion matrix to determine if a 72% is a good \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "X = application_df.drop('IS_SUCCESSFUL',axis=1)\n",
        "\n",
        "# Check the balance of our target values\n",
        "label_counts = y.value_counts()\n",
        "label_counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFl3VIb26u9j",
        "outputId": "d708ac17-115b-4914-ce58-71eb1bd673bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    18261\n",
              "0    16038\n",
              "Name: IS_SUCCESSFUL, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using the testing data\n",
        "pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bueNND-cBLFs",
        "outputId": "73d4cd68-7254-49ea-b675-1f49d46d2e6f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 0s 898us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions_df = pd.DataFrame({\"Prediction\": pred, \"Actual\": y_test})\n",
        "# predictions_df.head()"
      ],
      "metadata": {
        "id": "ZlzomogWBmQA"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}