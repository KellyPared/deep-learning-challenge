{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KellyPared/deep-learning-challenge/blob/main/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtQAKUl7xNO2"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67bCQJpsxLbu"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd \n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "NbXLN0DkX0eH",
        "outputId": "f8b700b3-5de7-47a6-b025-ffdf965fb460"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dbcb28a-1500-4f2d-9e62-4b2ffd916f42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dbcb28a-1500-4f2d-9e62-4b2ffd916f42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8dbcb28a-1500-4f2d-9e62-4b2ffd916f42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8dbcb28a-1500-4f2d-9e62-4b2ffd916f42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Import and read the charity_data.csv.\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtOpvWDy6rs",
        "outputId": "e6d4a92e-f6f7-4ca2-a03f-0e4b1ef2a8f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['EIN', 'NAME', 'APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION',\n",
              "       'USE_CASE', 'ORGANIZATION', 'STATUS', 'INCOME_AMT',\n",
              "       'SPECIAL_CONSIDERATIONS', 'ASK_AMT', 'IS_SUCCESSFUL'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "application_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYHnkkTO7Zf_",
        "outputId": "b7f9641a-ee3b-40de-b86c-0b161614cff5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    18261\n",
              "0    16038\n",
              "Name: IS_SUCCESSFUL, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#there is a fairly equal amount of is successful\n",
        "application_df['IS_SUCCESSFUL'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXTyIPqt3E1-"
      },
      "source": [
        "Goal: \"Wants a tool that can help it select the applicants for funding with the best chance of success..\"\n",
        "\n",
        "*   What variable(s) are the target(s) for your model?\n",
        "*   What variable(s) are the feature(s) for your model?\n",
        "\n",
        "\n",
        "### Target Variable is \"Is Successful\"\n",
        "### The other variables(Except EIN and NAME) are the features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9H9vh9yxRV6"
      },
      "outputs": [],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df.drop(['EIN', 'NAME'], axis=1, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQI7TF6m0_SU",
        "outputId": "2e22c3d6-b740-4e8c-a05c-e394a340b69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPLICATION_TYPE       : 17\n",
            "AFFILIATION            : 6\n",
            "CLASSIFICATION         : 71\n",
            "USE_CASE               : 5\n",
            "ORGANIZATION           : 4\n",
            "STATUS                 : 2\n",
            "INCOME_AMT             : 9\n",
            "SPECIAL_CONSIDERATIONS : 2\n",
            "ASK_AMT                : 8747\n",
            "IS_SUCCESSFUL          : 2\n"
          ]
        }
      ],
      "source": [
        "# calculate the number of unique values for each column\n",
        "for col in application_df.columns:\n",
        "    unique_vals = application_df[col].nunique()\n",
        "    #print(f\"{col}: {unique_vals}\")\n",
        "    print(\"{:<23}: {}\".format(col, unique_vals))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJMow3c1xRdr",
        "outputId": "795788c5-f6d4-46b6-f755-788b5715efb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T3     27037\n",
            "T4      1542\n",
            "T6      1216\n",
            "T5      1173\n",
            "T19     1065\n",
            "T8       737\n",
            "T7       725\n",
            "T10      528\n",
            "T9       156\n",
            "T13       66\n",
            "T12       27\n",
            "T2        16\n",
            "T25        3\n",
            "T14        3\n",
            "T29        2\n",
            "T15        2\n",
            "T17        1\n",
            "Name: APPLICATION_TYPE, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "# In ml, this column can be used as a feature to predict whether an organization will be successful in receiving funding.\n",
        "app_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "print(app_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpQFvf7QJKM",
        "outputId": "10c29e4b-2cb6-4716-994d-c9933ad8ec6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values for column 'APPLICATION_TYPE' (total: 17):\n",
            "T3     27037\n",
            "T4      1542\n",
            "T6      1216\n",
            "T5      1173\n",
            "T19     1065\n",
            "T8       737\n",
            "T7       725\n",
            "T10      528\n",
            "T9       156\n",
            "T13       66\n",
            "T12       27\n",
            "T2        16\n",
            "T25        3\n",
            "T14        3\n",
            "T29        2\n",
            "T15        2\n",
            "T17        1\n",
            "Name: APPLICATION_TYPE, dtype: int64\n",
            " \n",
            "Unique Values less than 10\n",
            "AFFILIATION            : 6\n",
            " \n",
            "Unique values for column 'CLASSIFICATION' (total: 71):\n",
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "         ...  \n",
            "C4120        1\n",
            "C8210        1\n",
            "C2561        1\n",
            "C4500        1\n",
            "C2150        1\n",
            "Name: CLASSIFICATION, Length: 71, dtype: int64\n",
            " \n",
            "Unique Values less than 10\n",
            "USE_CASE               : 5\n",
            " \n",
            "Unique Values less than 10\n",
            "ORGANIZATION           : 4\n",
            " \n",
            "Unique Values less than 10\n",
            "STATUS                 : 2\n",
            " \n",
            "Unique Values less than 10\n",
            "INCOME_AMT             : 9\n",
            " \n",
            "Unique Values less than 10\n",
            "SPECIAL_CONSIDERATIONS : 2\n",
            " \n",
            "Unique values for column 'ASK_AMT' (total: 8747):\n",
            "5000        25398\n",
            "10478           3\n",
            "15583           3\n",
            "63981           3\n",
            "6725            3\n",
            "            ...  \n",
            "5371754         1\n",
            "30060           1\n",
            "43091152        1\n",
            "18683           1\n",
            "36500179        1\n",
            "Name: ASK_AMT, Length: 8747, dtype: int64\n",
            " \n",
            "Unique Values less than 10\n",
            "IS_SUCCESSFUL          : 2\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# calculate the number of unique values for each column\n",
        "for col in application_df.columns:\n",
        "    unique_vals = application_df[col].nunique()\n",
        "\n",
        "    #For columns that have more than 10 unique values, determine the number of data points for each unique value.\n",
        "    #anything else. just print\n",
        "    \n",
        "    if unique_vals > 10:\n",
        "        print(\"Unique values for column '{}' (total: {}):\".format(col, unique_vals))\n",
        "        print(application_df[col].value_counts())\n",
        "        print(\" \")\n",
        "\n",
        "    else:\n",
        "        print(\"Unique Values less than 10\")\n",
        "        print(\"{:<23}: {}\".format(col, unique_vals))\n",
        "        print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt2K_gqlYZ1J"
      },
      "source": [
        "There are 17 different T types of the application type; T-codes might correspond to different types of activities that the organization performs, such as training and technical assistance, consulting, research and evaluation, information dissemination\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZR8f8ysZnBl"
      },
      "source": [
        "Choose a cutoff value that captures the majority of the variation in the data while still allowing you to bin the less common values into a single category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm1d-Hu2xRgc",
        "outputId": "ae859463-88f8-4576-ff72-61a705dec127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T9', 'T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']\n"
          ]
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "\n",
        "# The items below 500 are less frequent\n",
        "#A good rule of thumb is to choose a cutoff value that reduces the number \n",
        "# of unique values in the column to a manageable number\n",
        "cutoff = 500\n",
        "\n",
        "type_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "\n",
        "# application types less frequently than the cutoff\n",
        "application_types_to_replace = list(type_counts[type_counts < cutoff].index)\n",
        "\n",
        "print(application_types_to_replace)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4wnc0KlxRjH",
        "outputId": "7abef476-8974-4f79-9c45-4ff881ee10a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dNCUk8Cb1Yf"
      },
      "source": [
        "This information is important because it can help us to decide how to handle infrequent values in the CLASSIFICATION column. One common approach is to bin the infrequent values together into a single category. This can help to reduce the dimensionality of the data and"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz7SUaxcxRlm",
        "outputId": "f68ba357-f51e-4b00-97ba-8396164e4b5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: CLASSIFICATION, Length: 71, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts for \n",
        "#use this information to determine which values occur frequently and which values occur infrequently\n",
        "\n",
        "classification_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classification_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPCOWYeqb8NV",
        "outputId": "f668b0e0-fb8f-42db-b833-6e7d71539d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "C7000      777\n",
            "C1700      287\n",
            "C4000      194\n",
            "C5000      116\n",
            "C1270      114\n",
            "C2700      104\n",
            "C2800       95\n",
            "C7100       75\n",
            "C1300       58\n",
            "C1280       50\n",
            "C1230       36\n",
            "C1400       34\n",
            "C7200       32\n",
            "C2300       32\n",
            "C1240       30\n",
            "C8000       20\n",
            "C7120       18\n",
            "C1500       16\n",
            "C1800       15\n",
            "C6000       15\n",
            "C1250       14\n",
            "C8200       11\n",
            "C1238       10\n",
            "C1278       10\n",
            "C1235        9\n",
            "C1237        9\n",
            "C7210        7\n",
            "C2400        6\n",
            "C1720        6\n",
            "C4100        6\n",
            "C1257        5\n",
            "C1600        5\n",
            "C1260        3\n",
            "C2710        3\n",
            "C0           3\n",
            "C3200        2\n",
            "C1234        2\n",
            "C1246        2\n",
            "C1267        2\n",
            "C1256        2\n",
            "Name: CLASSIFICATION, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "\n",
        "classification_counts_over_1 = classification_counts[classification_counts > 1]\n",
        "print(classification_counts_over_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts7-rzyntdKV",
        "outputId": "c140321d-54ca-41a3-8359-76c3e7dace42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C1700',\n",
              " 'C4000',\n",
              " 'C5000',\n",
              " 'C1270',\n",
              " 'C2700',\n",
              " 'C2800',\n",
              " 'C7100',\n",
              " 'C1300',\n",
              " 'C1280',\n",
              " 'C1230',\n",
              " 'C1400',\n",
              " 'C7200',\n",
              " 'C2300',\n",
              " 'C1240',\n",
              " 'C8000',\n",
              " 'C7120',\n",
              " 'C1500',\n",
              " 'C1800',\n",
              " 'C6000',\n",
              " 'C1250',\n",
              " 'C8200',\n",
              " 'C1238',\n",
              " 'C1278',\n",
              " 'C1235',\n",
              " 'C1237',\n",
              " 'C7210',\n",
              " 'C2400',\n",
              " 'C1720',\n",
              " 'C4100',\n",
              " 'C1257',\n",
              " 'C1600',\n",
              " 'C1260',\n",
              " 'C2710',\n",
              " 'C0',\n",
              " 'C3200',\n",
              " 'C1234',\n",
              " 'C1246',\n",
              " 'C1267',\n",
              " 'C1256',\n",
              " 'C2190',\n",
              " 'C4200',\n",
              " 'C2600',\n",
              " 'C5200',\n",
              " 'C1370',\n",
              " 'C1248',\n",
              " 'C6100',\n",
              " 'C1820',\n",
              " 'C1900',\n",
              " 'C1236',\n",
              " 'C3700',\n",
              " 'C2570',\n",
              " 'C1580',\n",
              " 'C1245',\n",
              " 'C2500',\n",
              " 'C1570',\n",
              " 'C1283',\n",
              " 'C2380',\n",
              " 'C1732',\n",
              " 'C1728',\n",
              " 'C2170',\n",
              " 'C4120',\n",
              " 'C8210',\n",
              " 'C2561',\n",
              " 'C4500',\n",
              " 'C2150']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "cutoff2 = 300\n",
        "# use the variable name `classifications_to_replace`\n",
        "# Get the counts of each application type\n",
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "classifications_to_replace =  list(class_counts[class_counts < cutoff2].index)\n",
        "\n",
        "classifications_to_replace \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXZNxBq_0y38",
        "outputId": "40ffd1f1-a182-41bc-cd26-3b864d5c9d4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Other     1484\n",
              "C7000      777\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR6boyCJ1I-E",
        "outputId": "e947583c-cacf-4dec-8625-93b257a32575"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE',\n",
              "       'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "# identify the categorical columns\n",
        "cat_cols = application_df.select_dtypes(include=['object']).columns\n",
        "cat_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "gGvPBlyX8ywY",
        "outputId": "ead0730d-1a63-4d12-9989-2185194b2620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
              "0                     0.0                   1.0                   0.0   \n",
              "1                     0.0                   0.0                   0.0   \n",
              "2                     0.0                   0.0                   0.0   \n",
              "3                     0.0                   0.0                   0.0   \n",
              "4                     0.0                   0.0                   0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
              "0                  0.0                  0.0                  0.0   \n",
              "1                  1.0                  0.0                  0.0   \n",
              "2                  0.0                  0.0                  1.0   \n",
              "3                  1.0                  0.0                  0.0   \n",
              "4                  1.0                  0.0                  0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
              "0                  0.0                  0.0                  0.0   \n",
              "1                  0.0                  0.0                  0.0   \n",
              "2                  0.0                  0.0                  0.0   \n",
              "3                  0.0                  0.0                  0.0   \n",
              "4                  0.0                  0.0                  0.0   \n",
              "\n",
              "   AFFILIATION_CompanySponsored  ...  INCOME_AMT_1-9999  \\\n",
              "0                           0.0  ...                0.0   \n",
              "1                           0.0  ...                1.0   \n",
              "2                           1.0  ...                0.0   \n",
              "3                           1.0  ...                0.0   \n",
              "4                           0.0  ...                0.0   \n",
              "\n",
              "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                     0.0                       0.0                 0.0   \n",
              "1                     0.0                       0.0                 0.0   \n",
              "2                     0.0                       0.0                 0.0   \n",
              "3                     1.0                       0.0                 0.0   \n",
              "4                     0.0                       1.0                 0.0   \n",
              "\n",
              "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0               0.0                     0.0              0.0   \n",
              "1               0.0                     0.0              0.0   \n",
              "2               0.0                     0.0              0.0   \n",
              "3               0.0                     0.0              0.0   \n",
              "4               0.0                     0.0              0.0   \n",
              "\n",
              "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
              "0                0.0                       1.0                       0.0  \n",
              "1                0.0                       1.0                       0.0  \n",
              "2                0.0                       1.0                       0.0  \n",
              "3                0.0                       1.0                       0.0  \n",
              "4                0.0                       1.0                       0.0  \n",
              "\n",
              "[5 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47bbb330-91ff-4b60-a246-2accb7d06490\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47bbb330-91ff-4b60-a246-2accb7d06490')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47bbb330-91ff-4b60-a246-2accb7d06490 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47bbb330-91ff-4b60-a246-2accb7d06490');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#OneHotEncoder\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "encoded_df = pd.DataFrame(enc.fit_transform(application_df[cat_cols]))\n",
        "encoded_df.columns = enc.get_feature_names_out()\n",
        "encoded_df.head()\n",
        "\n",
        "# convert the categorical columns to dummy variables\n",
        "# final_df = pd.get_dummies(application_df, columns=cat_cols)\n",
        "\n",
        "# apply one-hot encoding using pd.get_dummies\n",
        "# final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "MngCIxay0IeV",
        "outputId": "1d19fce5-56fd-4b6c-e2c5-2c351f8b378a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-fba0bef732c8>:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  application_df = application_df.drop(cat_cols,1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                     0.0   \n",
              "1       1   108590              1                     0.0   \n",
              "2       1     5000              0                     0.0   \n",
              "3       1     6692              1                     0.0   \n",
              "4       1   142590              1                     0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                   1.0                   0.0                  0.0   \n",
              "1                   0.0                   0.0                  1.0   \n",
              "2                   0.0                   0.0                  0.0   \n",
              "3                   0.0                   0.0                  1.0   \n",
              "4                   0.0                   0.0                  1.0   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                  0.0                  0.0                  0.0  ...   \n",
              "1                  0.0                  0.0                  0.0  ...   \n",
              "2                  0.0                  1.0                  0.0  ...   \n",
              "3                  0.0                  0.0                  0.0  ...   \n",
              "4                  0.0                  0.0                  0.0  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                0.0                     0.0                       0.0   \n",
              "1                1.0                     0.0                       0.0   \n",
              "2                0.0                     0.0                       0.0   \n",
              "3                0.0                     1.0                       0.0   \n",
              "4                0.0                     0.0                       1.0   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                 0.0               0.0                     0.0   \n",
              "1                 0.0               0.0                     0.0   \n",
              "2                 0.0               0.0                     0.0   \n",
              "3                 0.0               0.0                     0.0   \n",
              "4                 0.0               0.0                     0.0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0              0.0                0.0                       1.0   \n",
              "1              0.0                0.0                       1.0   \n",
              "2              0.0                0.0                       1.0   \n",
              "3              0.0                0.0                       1.0   \n",
              "4              0.0                0.0                       1.0   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                       0.0  \n",
              "1                       0.0  \n",
              "2                       0.0  \n",
              "3                       0.0  \n",
              "4                       0.0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e634d0f-e8c2-41be-9996-ffebbc2a0cc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e634d0f-e8c2-41be-9996-ffebbc2a0cc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e634d0f-e8c2-41be-9996-ffebbc2a0cc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e634d0f-e8c2-41be-9996-ffebbc2a0cc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from IPython.core import application\n",
        "#merge one-hot encoder and drop originals\n",
        "\n",
        "application_df = application_df.merge(encoded_df, left_index=True, right_index =True)\n",
        "application_df = application_df.drop(cat_cols,1)\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slX6sR8j9xyC",
        "outputId": "7c199581-b3ea-4d73-9e9d-2a8de3c22bb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['STATUS', 'ASK_AMT', 'IS_SUCCESSFUL', 'APPLICATION_TYPE_Other',\n",
              "       'APPLICATION_TYPE_T10', 'APPLICATION_TYPE_T19', 'APPLICATION_TYPE_T3',\n",
              "       'APPLICATION_TYPE_T4', 'APPLICATION_TYPE_T5', 'APPLICATION_TYPE_T6',\n",
              "       'APPLICATION_TYPE_T7', 'APPLICATION_TYPE_T8',\n",
              "       'AFFILIATION_CompanySponsored', 'AFFILIATION_Family/Parent',\n",
              "       'AFFILIATION_Independent', 'AFFILIATION_National', 'AFFILIATION_Other',\n",
              "       'AFFILIATION_Regional', 'CLASSIFICATION_C1000', 'CLASSIFICATION_C1200',\n",
              "       'CLASSIFICATION_C2000', 'CLASSIFICATION_C2100', 'CLASSIFICATION_C3000',\n",
              "       'CLASSIFICATION_C7000', 'CLASSIFICATION_Other',\n",
              "       'USE_CASE_CommunityServ', 'USE_CASE_Heathcare', 'USE_CASE_Other',\n",
              "       'USE_CASE_Preservation', 'USE_CASE_ProductDev',\n",
              "       'ORGANIZATION_Association', 'ORGANIZATION_Co-operative',\n",
              "       'ORGANIZATION_Corporation', 'ORGANIZATION_Trust', 'INCOME_AMT_0',\n",
              "       'INCOME_AMT_1-9999', 'INCOME_AMT_10000-24999',\n",
              "       'INCOME_AMT_100000-499999', 'INCOME_AMT_10M-50M', 'INCOME_AMT_1M-5M',\n",
              "       'INCOME_AMT_25000-99999', 'INCOME_AMT_50M+', 'INCOME_AMT_5M-10M',\n",
              "       'SPECIAL_CONSIDERATIONS_N', 'SPECIAL_CONSIDERATIONS_Y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "application_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kie62IzP1JxZ"
      },
      "outputs": [],
      "source": [
        "#Split our preproesssed data into our features and target arrays\n",
        "X = application_df.drop('IS_SUCCESSFUL', axis=1).values # remove the target column\n",
        "y = application_df['IS_SUCCESSFUL'].values # set the target column as the target variable\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygy8IpZt-rJz",
        "outputId": "d6ee12d4-c5e8-47a8-eb16-2d49aec7fdf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (25724, 44)\n",
            "y_train shape: (25724,)\n",
            "X_test shape: (8575, 44)\n",
            "y_test shape: (8575,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbNeJRDa1Lkf"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHjRF3fCDIxM"
      },
      "source": [
        "## Compile, Train and Evaluate the Model\n",
        "Create a neural network model by assigning the number of input features and nodes for each layer using TensorFlow and Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L88ovrqf2TZk",
        "outputId": "a06cef26-9662-4ef0-b72b-41138d4942a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#Sequential = layers are stacked on top of each other in sequence\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#the number of input features - this is the length of the training -pick any column\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "print(number_input_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A06CBVgQDKM_",
        "outputId": "85f00704-1435-4a1e-813f-5db041bee44e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 30)                1350      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,991\n",
            "Trainable params: 1,991\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#hidden nodes for each layer pick a random number\n",
        "units_layer1 = 30\n",
        "units_layer2 = 20\n",
        "\n",
        "#the more layers - \n",
        "# First hidden layer\n",
        "model.add(Dense(units=units_layer1, \n",
        "                                activation='relu', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(units=units_layer2, \n",
        "                                activation='relu', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq6ParogDMLg"
      },
      "outputs": [],
      "source": [
        "# Compile the model - \n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VjHEBSTDONl",
        "outputId": "9af7e54c-b2cf-47cf-8808-adcb4d74e29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 weights:\n",
            "[[ 0.25771114  0.18496674 -0.15579353 ... -0.07107361 -0.17937255\n",
            "   0.1996718 ]\n",
            " [-0.07292433  0.1216557   0.09530607 ...  0.01155147  0.01945633\n",
            "  -0.13254458]\n",
            " [-0.13118964  0.04693368  0.06798553 ... -0.2325356  -0.00599176\n",
            "   0.21409911]\n",
            " ...\n",
            " [ 0.01372567 -0.10868219  0.20853004 ... -0.2637297  -0.11491522\n",
            "  -0.25323975]\n",
            " [-0.01557893  0.24958447  0.20713273 ...  0.06100607  0.12234181\n",
            "   0.23898098]\n",
            " [ 0.05410412  0.27603754  0.05135897 ...  0.228547   -0.24224204\n",
            "   0.24977145]]\n",
            "Layer 1 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "Layer 2 weights:\n",
            "[[-0.31530982 -0.07072169 -0.25197917  0.17618197 -0.2151953   0.22558278\n",
            "   0.223355    0.02950037  0.21674955 -0.01716077 -0.3249783  -0.2730639\n",
            "   0.17504007 -0.05493036  0.17118543  0.18238604 -0.3044101   0.26369804\n",
            "   0.03090492 -0.00639531]\n",
            " [-0.12541592 -0.09566206 -0.23780945  0.09924343 -0.12809375  0.13082412\n",
            "  -0.00253868  0.0320887   0.33468693 -0.02698484 -0.32332334  0.07630628\n",
            "  -0.21064812 -0.18876779 -0.19654138 -0.07425606  0.19237715 -0.13259313\n",
            "  -0.0319382  -0.18112303]\n",
            " [-0.24171853  0.17132157 -0.11479212 -0.22876114  0.05889297  0.13601437\n",
            "   0.19114739 -0.2391029   0.23136556 -0.01479074 -0.31936693  0.1366806\n",
            "  -0.30614212 -0.28863877  0.18641949 -0.10895866 -0.0650079   0.29333413\n",
            "   0.1717462  -0.07199466]\n",
            " [ 0.23658073  0.13912669 -0.15176083  0.18843246  0.3033855  -0.03652453\n",
            "  -0.26897442 -0.08456603  0.30274695  0.24495715  0.02947691  0.12209338\n",
            "  -0.17347424 -0.05471644  0.21360683 -0.3333064   0.07724386  0.03330499\n",
            "   0.04594922  0.02247298]\n",
            " [ 0.24029988 -0.14263383 -0.10061271 -0.17382963  0.20626283 -0.2450841\n",
            "   0.10170951 -0.24518429 -0.24386862 -0.3419547   0.10270944 -0.12435612\n",
            "  -0.02418351 -0.08731282 -0.22389945 -0.27818602  0.07907894 -0.07247138\n",
            "   0.12366435  0.19300818]\n",
            " [-0.02664167 -0.31812593  0.06741104  0.3022275   0.1567623  -0.2923285\n",
            "   0.25555444 -0.04567865  0.21668679 -0.13933441 -0.28409538 -0.30316505\n",
            "   0.20247793  0.0554364  -0.19504799 -0.21726386 -0.21779889 -0.2557074\n",
            "  -0.33841613  0.24957514]\n",
            " [ 0.1297786   0.01119715 -0.24413234 -0.2780025   0.20147318 -0.3053232\n",
            "   0.22196132  0.06504458 -0.05208859 -0.15708794  0.03181654  0.09458095\n",
            "  -0.00617224 -0.17961057 -0.3035134   0.16531551  0.26485842  0.2843954\n",
            "  -0.19476412  0.08904541]\n",
            " [ 0.02901483 -0.30567226 -0.08980846 -0.22293371  0.32141805  0.02441379\n",
            "  -0.21168305  0.2833221  -0.04142901  0.13070098  0.2788254  -0.19179499\n",
            "  -0.00621569 -0.09576678 -0.18967985  0.06379738  0.148907    0.07085004\n",
            "  -0.16723584  0.11809757]\n",
            " [-0.31078964  0.23794603 -0.28700984  0.02011329 -0.00498426 -0.01166013\n",
            "  -0.24980119 -0.31655192  0.02896181  0.30498135  0.00471979 -0.16304453\n",
            "  -0.27112475  0.16050494  0.14027718 -0.06583232 -0.20894097  0.2409758\n",
            "   0.23870271  0.00687701]\n",
            " [ 0.29670644 -0.03064847  0.21971226  0.20787114 -0.21404754  0.11211652\n",
            "   0.25496376  0.26544625 -0.03114212  0.09435284  0.06615716  0.2065134\n",
            "  -0.33486456 -0.15009457  0.2825325   0.32051724  0.23369396 -0.06770596\n",
            "   0.19429755 -0.25081375]\n",
            " [ 0.26810634 -0.28503162  0.21164638 -0.25693703  0.23318404 -0.21074863\n",
            "  -0.10862656 -0.2643891   0.3087911   0.05353186  0.14176184  0.16269577\n",
            "  -0.01564309  0.16330409 -0.1695065  -0.2329584   0.0671863   0.04947352\n",
            "   0.05982706  0.064477  ]\n",
            " [-0.02915332 -0.28641483  0.31171304  0.08183879 -0.223338   -0.11679462\n",
            "  -0.32095003  0.14777634 -0.22501409  0.01613376 -0.05808327 -0.16112232\n",
            "   0.03471202 -0.13228746 -0.29761222 -0.11836424  0.31041318 -0.03747293\n",
            "  -0.334772    0.3202994 ]\n",
            " [-0.2451629  -0.07493225 -0.23993656  0.22893304 -0.00817811 -0.19148254\n",
            "   0.21472234  0.2583509   0.2762395   0.07439458  0.18283623  0.22856969\n",
            "  -0.21439435  0.17660308 -0.10888797 -0.3017383   0.09442726  0.32088542\n",
            "  -0.01553077 -0.32746974]\n",
            " [ 0.21223956  0.22577846 -0.32942978  0.20862728 -0.3314881  -0.27199617\n",
            "  -0.22645116  0.15630227 -0.13708688  0.34409463 -0.2729435   0.26877373\n",
            "  -0.07986107  0.29814875  0.21767962  0.24092948  0.0275172  -0.00742358\n",
            "   0.14224425  0.22976059]\n",
            " [-0.1203323  -0.262089   -0.03854206  0.19943142  0.29706645 -0.32086834\n",
            "  -0.23789972 -0.2681265  -0.2528938   0.00359815 -0.27929032  0.1377368\n",
            "  -0.11982056 -0.30915096 -0.09724995 -0.0663316  -0.03578669 -0.01222655\n",
            "  -0.28646448 -0.27282447]\n",
            " [ 0.22354949 -0.20766106 -0.32132357  0.0267905   0.03630105  0.26524496\n",
            "   0.13720483 -0.17924708 -0.06412995 -0.05715123  0.33101815 -0.04955512\n",
            "  -0.20133916  0.12732235  0.02867967 -0.24821958  0.31827837 -0.32018325\n",
            "   0.05222988  0.08911744]\n",
            " [-0.2658223   0.02066889 -0.19671243 -0.13015357  0.31763268 -0.20831427\n",
            "   0.2588007   0.14728054  0.10822856  0.00219387 -0.28287023 -0.0194335\n",
            "  -0.09504694  0.30394948  0.20947897 -0.26972228  0.25402892 -0.286779\n",
            "   0.33029556  0.13930014]\n",
            " [-0.10442667 -0.07467338  0.06762511  0.02775186 -0.0492644  -0.21763816\n",
            "  -0.21691178 -0.17498697 -0.20482986 -0.03378767  0.22963297 -0.04402328\n",
            "   0.09597152  0.23683465 -0.13059369 -0.07658422  0.09533435 -0.3260941\n",
            "  -0.04893041  0.15987444]\n",
            " [-0.11698747  0.13275203  0.30142343  0.17132819  0.15549576 -0.12248453\n",
            "  -0.21734744 -0.17218831 -0.1151385  -0.29737166  0.04048344 -0.14983317\n",
            "   0.3182649  -0.18436034 -0.02820644 -0.0355275   0.2505051   0.12953529\n",
            "   0.34625536  0.2754923 ]\n",
            " [ 0.16309863 -0.12425354  0.2731499   0.34600115  0.00775558  0.05586174\n",
            "   0.28144217  0.30586022  0.11546046  0.34314483 -0.24065246 -0.26877704\n",
            "  -0.02536291 -0.27316788  0.30486566  0.28214145 -0.22810487 -0.01631379\n",
            "  -0.06743911  0.10951301]\n",
            " [ 0.21966535  0.02978805 -0.27403623 -0.09156013  0.19712734 -0.1797104\n",
            "   0.24151278  0.33344048  0.33511937 -0.2762102  -0.2967595  -0.24545725\n",
            "   0.12263155 -0.3249537  -0.19883443  0.3287158  -0.13287021  0.13823432\n",
            "   0.3137439  -0.27321067]\n",
            " [-0.30745843  0.04611579 -0.02501595  0.17350948 -0.2126221   0.14133814\n",
            "   0.16292346  0.3433709  -0.00321707  0.1694206  -0.00156534  0.11303392\n",
            "   0.22351843  0.01567817  0.1856919  -0.2089664  -0.17443782 -0.2042338\n",
            "  -0.11002573 -0.03954521]\n",
            " [ 0.30610478 -0.11864869 -0.15594025 -0.1846044   0.18906438  0.20329976\n",
            "   0.31173372  0.27270818  0.16521072 -0.1428128  -0.09077063 -0.11392178\n",
            "  -0.31748164  0.09143078 -0.2687906   0.14550832 -0.16604471  0.18624306\n",
            "   0.29819077  0.17914832]\n",
            " [-0.02449167 -0.16492042  0.1461545  -0.3139902  -0.12047575 -0.11594047\n",
            "  -0.18161577  0.0435715   0.2615577   0.12184891 -0.00439176  0.00718322\n",
            "   0.24523216  0.27358413 -0.19064268 -0.03006297 -0.06685859  0.29701823\n",
            "   0.31775582 -0.12047857]\n",
            " [ 0.02588505 -0.29053536 -0.01215559 -0.09391841  0.20045501 -0.21800041\n",
            "  -0.29922894  0.12568325 -0.2046223   0.29172915  0.03366575  0.07124242\n",
            "   0.21349907  0.16468066 -0.3408847  -0.02394369 -0.17456163 -0.15698808\n",
            "   0.14532232  0.31146252]\n",
            " [-0.12393433  0.14627674  0.07445347 -0.2807104   0.3042764   0.15767789\n",
            "   0.09566084  0.33582532 -0.00442693  0.01351744 -0.3428846   0.06377169\n",
            "  -0.03373736  0.11367103 -0.04109371  0.14610064 -0.06640574 -0.1768877\n",
            "   0.12119859  0.1487067 ]\n",
            " [-0.02941415  0.23192108 -0.01286367 -0.161806    0.31455064  0.12875283\n",
            "   0.21570098 -0.19509332 -0.10040301 -0.1185656  -0.32702523 -0.30739245\n",
            "   0.08221391 -0.21506597 -0.00630537  0.17305005 -0.25711575  0.07420668\n",
            "   0.16450739 -0.03031233]\n",
            " [ 0.2764622  -0.34197596 -0.3249381  -0.19098502  0.05196881  0.20746273\n",
            "   0.02813151 -0.34447134 -0.19684318  0.31948024  0.2942326  -0.19470763\n",
            "  -0.34598538 -0.11810781  0.07297367  0.3425284   0.2074523  -0.30861083\n",
            "   0.31317657 -0.11894552]\n",
            " [-0.04741636  0.1543181   0.05226961  0.05272982  0.10532004  0.23744267\n",
            "  -0.20478393 -0.26640487 -0.12457143 -0.3372208  -0.29767054  0.32404578\n",
            "   0.12336206 -0.22571123 -0.10285208  0.00837734  0.1598512   0.20966017\n",
            "   0.23848915 -0.25213802]\n",
            " [-0.2326752  -0.295516    0.03198537 -0.33178312  0.16975361 -0.1989745\n",
            "   0.1193285  -0.00358799 -0.00926444 -0.06465921 -0.17062445 -0.00742018\n",
            "  -0.29071203 -0.16187249 -0.02070209  0.06823793  0.29891312  0.17292172\n",
            "   0.02688366 -0.07133797]]\n",
            "Layer 3 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer 4 weights:\n",
            "[[-5.1168591e-02]\n",
            " [ 4.3994743e-01]\n",
            " [-5.0143611e-01]\n",
            " [-3.3654162e-01]\n",
            " [ 4.2980164e-01]\n",
            " [ 2.9359865e-01]\n",
            " [-3.1671941e-02]\n",
            " [ 4.2467755e-01]\n",
            " [ 3.5648167e-02]\n",
            " [-2.3076367e-01]\n",
            " [-1.4656782e-04]\n",
            " [-4.6764815e-01]\n",
            " [ 5.2459830e-01]\n",
            " [ 1.0242665e-01]\n",
            " [ 5.3377628e-02]\n",
            " [ 3.6033100e-01]\n",
            " [ 3.3965534e-01]\n",
            " [-2.1375540e-01]\n",
            " [-4.0499645e-01]\n",
            " [ 4.0585297e-01]]\n",
            "Layer 5 weights:\n",
            "[0.]\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 15s 15ms/step - loss: 0.5786 - accuracy: 0.7143 - val_loss: 10768.6826 - val_accuracy: 0.4657\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.5559 - accuracy: 0.7275 - val_loss: 20476.5938 - val_accuracy: 0.5343\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5530 - accuracy: 0.7287 - val_loss: 16544.3965 - val_accuracy: 0.4657\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5514 - accuracy: 0.7307 - val_loss: 18653.2637 - val_accuracy: 0.5343\n",
            "Epoch 5/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5495 - accuracy: 0.7302\n",
            "Epoch 5: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5497 - accuracy: 0.7298 - val_loss: 69852.7422 - val_accuracy: 0.5343\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7310 - val_loss: 50611.5664 - val_accuracy: 0.5343\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7318 - val_loss: 30905.8535 - val_accuracy: 0.5343\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5474 - accuracy: 0.7312 - val_loss: 54127.4922 - val_accuracy: 0.5343\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5462 - accuracy: 0.7331 - val_loss: 41858.1875 - val_accuracy: 0.5343\n",
            "Epoch 10/100\n",
            "787/804 [============================>.] - ETA: 0s - loss: 0.5466 - accuracy: 0.7309\n",
            "Epoch 10: saving model to model_weights.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5461 - accuracy: 0.7315 - val_loss: 61854.8828 - val_accuracy: 0.5343\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7321 - val_loss: 6971.3091 - val_accuracy: 0.5343\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5456 - accuracy: 0.7328 - val_loss: 19604.1680 - val_accuracy: 0.5343\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7317 - val_loss: 15413.0498 - val_accuracy: 0.5343\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7322 - val_loss: 15170.2637 - val_accuracy: 0.5343\n",
            "Epoch 15/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5434 - accuracy: 0.7333\n",
            "Epoch 15: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7328 - val_loss: 12983.8643 - val_accuracy: 0.4657\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7320 - val_loss: 16970.6582 - val_accuracy: 0.5343\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7333 - val_loss: 15472.2715 - val_accuracy: 0.5343\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7331 - val_loss: 16635.3340 - val_accuracy: 0.5343\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7335 - val_loss: 33620.3242 - val_accuracy: 0.5343\n",
            "Epoch 20/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5431 - accuracy: 0.7324\n",
            "Epoch 20: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7328 - val_loss: 65834.8984 - val_accuracy: 0.5343\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7342 - val_loss: 25131.9902 - val_accuracy: 0.5343\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5428 - accuracy: 0.7334 - val_loss: 22477.7324 - val_accuracy: 0.5343\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7345 - val_loss: 22233.5840 - val_accuracy: 0.5343\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7347 - val_loss: 19998.1914 - val_accuracy: 0.5343\n",
            "Epoch 25/100\n",
            "800/804 [============================>.] - ETA: 0s - loss: 0.5421 - accuracy: 0.7346\n",
            "Epoch 25: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7346 - val_loss: 37088.7109 - val_accuracy: 0.5343\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7336 - val_loss: 20881.7266 - val_accuracy: 0.5343\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7340 - val_loss: 39745.8828 - val_accuracy: 0.5343\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5416 - accuracy: 0.7358 - val_loss: 35980.4336 - val_accuracy: 0.5343\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7351 - val_loss: 42297.5938 - val_accuracy: 0.5343\n",
            "Epoch 30/100\n",
            "779/804 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.7358\n",
            "Epoch 30: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5412 - accuracy: 0.7357 - val_loss: 4861.7144 - val_accuracy: 0.5343\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7344 - val_loss: 66431.7578 - val_accuracy: 0.5343\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5410 - accuracy: 0.7358 - val_loss: 35056.4766 - val_accuracy: 0.5343\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7357 - val_loss: 30801.5879 - val_accuracy: 0.5343\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5406 - accuracy: 0.7357 - val_loss: 54655.3008 - val_accuracy: 0.5343\n",
            "Epoch 35/100\n",
            "796/804 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.7362\n",
            "Epoch 35: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7361 - val_loss: 5391.0298 - val_accuracy: 0.4657\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5401 - accuracy: 0.7366 - val_loss: 12286.5371 - val_accuracy: 0.5343\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7368 - val_loss: 13518.1426 - val_accuracy: 0.5343\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7367 - val_loss: 23910.8965 - val_accuracy: 0.5343\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7371 - val_loss: 63486.1211 - val_accuracy: 0.5343\n",
            "Epoch 40/100\n",
            "787/804 [============================>.] - ETA: 0s - loss: 0.5393 - accuracy: 0.7377\n",
            "Epoch 40: saving model to model_weights.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5398 - accuracy: 0.7371 - val_loss: 35924.4297 - val_accuracy: 0.5343\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5395 - accuracy: 0.7369 - val_loss: 23574.1582 - val_accuracy: 0.5343\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7360 - val_loss: 44490.5195 - val_accuracy: 0.5343\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7364 - val_loss: 19583.2031 - val_accuracy: 0.5343\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7374 - val_loss: 58175.7930 - val_accuracy: 0.5343\n",
            "Epoch 45/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5389 - accuracy: 0.7373\n",
            "Epoch 45: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5393 - accuracy: 0.7369 - val_loss: 10785.4609 - val_accuracy: 0.5343\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7373 - val_loss: 18850.1445 - val_accuracy: 0.5343\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5388 - accuracy: 0.7371 - val_loss: 18038.0078 - val_accuracy: 0.5343\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7369 - val_loss: 60767.2578 - val_accuracy: 0.5343\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5386 - accuracy: 0.7372 - val_loss: 51841.7969 - val_accuracy: 0.5343\n",
            "Epoch 50/100\n",
            "779/804 [============================>.] - ETA: 0s - loss: 0.5390 - accuracy: 0.7377\n",
            "Epoch 50: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5389 - accuracy: 0.7375 - val_loss: 41241.4414 - val_accuracy: 0.5343\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7382 - val_loss: 41772.7266 - val_accuracy: 0.5343\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5389 - accuracy: 0.7366 - val_loss: 9.9482 - val_accuracy: 0.5791\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5385 - accuracy: 0.7382 - val_loss: 45819.8359 - val_accuracy: 0.5343\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7367 - val_loss: 25686.0137 - val_accuracy: 0.5343\n",
            "Epoch 55/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.7373\n",
            "Epoch 55: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7375 - val_loss: 41279.9844 - val_accuracy: 0.5343\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7379 - val_loss: 55744.6758 - val_accuracy: 0.5343\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5378 - accuracy: 0.7384 - val_loss: 7845.4941 - val_accuracy: 0.5343\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5380 - accuracy: 0.7373 - val_loss: 12625.5479 - val_accuracy: 0.5343\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7381 - val_loss: 45860.5195 - val_accuracy: 0.5343\n",
            "Epoch 60/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.7358\n",
            "Epoch 60: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7358 - val_loss: 8934.9531 - val_accuracy: 0.5343\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7383 - val_loss: 38133.2539 - val_accuracy: 0.5343\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7377 - val_loss: 35353.4258 - val_accuracy: 0.5343\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7381 - val_loss: 80158.1641 - val_accuracy: 0.5343\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5378 - accuracy: 0.7381 - val_loss: 10135.8916 - val_accuracy: 0.4657\n",
            "Epoch 65/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.7383\n",
            "Epoch 65: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5378 - accuracy: 0.7382 - val_loss: 60112.4062 - val_accuracy: 0.5343\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7385 - val_loss: 13204.3428 - val_accuracy: 0.5343\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7388 - val_loss: 75924.1094 - val_accuracy: 0.5343\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7379 - val_loss: 21650.5645 - val_accuracy: 0.5343\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7383 - val_loss: 25900.5273 - val_accuracy: 0.5343\n",
            "Epoch 70/100\n",
            "802/804 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.7383\n",
            "Epoch 70: saving model to model_weights.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5374 - accuracy: 0.7381 - val_loss: 42481.6016 - val_accuracy: 0.5343\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7379 - val_loss: 48353.8828 - val_accuracy: 0.5343\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7380 - val_loss: 5288.2217 - val_accuracy: 0.4657\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7389 - val_loss: 62672.5977 - val_accuracy: 0.5343\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7376 - val_loss: 10764.6553 - val_accuracy: 0.5343\n",
            "Epoch 75/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7386\n",
            "Epoch 75: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7389 - val_loss: 19935.4922 - val_accuracy: 0.5343\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5369 - accuracy: 0.7385 - val_loss: 33512.7383 - val_accuracy: 0.5343\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7380 - val_loss: 25413.7129 - val_accuracy: 0.5343\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.7386 - val_loss: 22937.1289 - val_accuracy: 0.5343\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7388 - val_loss: 971.4581 - val_accuracy: 0.5343\n",
            "Epoch 80/100\n",
            "789/804 [============================>.] - ETA: 0s - loss: 0.5361 - accuracy: 0.7390\n",
            "Epoch 80: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5365 - accuracy: 0.7388 - val_loss: 66433.5000 - val_accuracy: 0.5343\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5366 - accuracy: 0.7378 - val_loss: 12963.3213 - val_accuracy: 0.5343\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5367 - accuracy: 0.7394 - val_loss: 62330.2383 - val_accuracy: 0.5343\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.7390 - val_loss: 21253.7988 - val_accuracy: 0.5343\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5362 - accuracy: 0.7381 - val_loss: 807.1290 - val_accuracy: 0.5343\n",
            "Epoch 85/100\n",
            "796/804 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.7379\n",
            "Epoch 85: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.7376 - val_loss: 22432.9727 - val_accuracy: 0.5343\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7392 - val_loss: 56073.8398 - val_accuracy: 0.5343\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5365 - accuracy: 0.7392 - val_loss: 54304.7930 - val_accuracy: 0.5343\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5365 - accuracy: 0.7385 - val_loss: 9499.3740 - val_accuracy: 0.5343\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7377 - val_loss: 102267.4297 - val_accuracy: 0.5343\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.7381\n",
            "Epoch 90: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7381 - val_loss: 33424.9375 - val_accuracy: 0.5343\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7389 - val_loss: 20628.6172 - val_accuracy: 0.5343\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5365 - accuracy: 0.7390 - val_loss: 50520.9180 - val_accuracy: 0.5343\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5358 - accuracy: 0.7388 - val_loss: 95900.2812 - val_accuracy: 0.5343\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5360 - accuracy: 0.7381 - val_loss: 43730.6641 - val_accuracy: 0.5343\n",
            "Epoch 95/100\n",
            "797/804 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.7382\n",
            "Epoch 95: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5361 - accuracy: 0.7377 - val_loss: 41307.8125 - val_accuracy: 0.5343\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5360 - accuracy: 0.7383 - val_loss: 69277.7500 - val_accuracy: 0.5343\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5360 - accuracy: 0.7389 - val_loss: 63974.1328 - val_accuracy: 0.5343\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5358 - accuracy: 0.7387 - val_loss: 84120.4141 - val_accuracy: 0.5343\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5361 - accuracy: 0.7397 - val_loss: 6603.4497 - val_accuracy: 0.5343\n",
            "Epoch 100/100\n",
            "788/804 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.7393\n",
            "Epoch 100: saving model to model_weights.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5357 - accuracy: 0.7388 - val_loss: 45634.1914 - val_accuracy: 0.5343\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe2c342ff70>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "\n",
        "# Define the checkpoint file path\n",
        "checkpoint_filepath = 'model_weights.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    period=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "weights = model.get_weights()\n",
        "for i, layer_weights in enumerate(weights):\n",
        "    print(f'Layer {i} weights:')\n",
        "    print(layer_weights)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train,epochs=100,\n",
        "          validation_data=(X_test, y_test),\n",
        "    callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5UsF2zMDQZf",
        "outputId": "4e98e23c-13ed-47c7-8c0b-45c6a0895930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5562 - accuracy: 0.7292 - 342ms/epoch - 1ms/step\n",
            "Loss: 0.556181788444519, Accuracy: 0.7292128205299377\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJE2SDxyDUZ5"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "# save the model to an HDF5 file\n",
        "model.save('AlphabetSoupCharity.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXxBYoFQz6eS"
      },
      "source": [
        "# Optimizing the Model: Trial 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s1QXT4C112l",
        "outputId": "5038b828-135c-4b8d-b0db-38d8a260844b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#Sequential = layers are stacked on top of each other in sequence\n",
        "model2 = tf.keras.models.Sequential()\n",
        "\n",
        "#the number of input features - this is the length of the training -pick any column\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "print(number_input_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXY8DJmh1psa",
        "outputId": "b42ea580-01b3-4e8a-b8ec-9f71d15dd3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 50)                2250      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 30)                1530      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,811\n",
            "Trainable params: 3,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#hidden nodes for each layer pick a random number\n",
        "units_layer1 = 50\n",
        "units_layer2 = 30\n",
        "\n",
        "#the more layers - \n",
        "# First hidden layer\n",
        "model2.add(Dense(units=units_layer1, \n",
        "                                activation='relu', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "model2.add(Dense(units=units_layer2, \n",
        "                                activation='tanh', \n",
        "                                input_dim=number_input_features))\n",
        "\n",
        "# Output layer\n",
        "model2.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-n7x57L2M0F"
      },
      "outputs": [],
      "source": [
        "# Compile the model - \n",
        "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Le5LVZ2fez",
        "outputId": "94033070-4fa4-46a1-a979-6775bec3da3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 weights:\n",
            "[[ 0.02731797 -0.17188774  0.06687877 ... -0.00210789 -0.23898178\n",
            "  -0.00862637]\n",
            " [-0.13525498  0.15348276 -0.17780712 ...  0.12079975  0.16386631\n",
            "  -0.14081699]\n",
            " [ 0.10432333  0.00683907  0.06896609 ...  0.17778093 -0.24339162\n",
            "   0.02867863]\n",
            " ...\n",
            " [ 0.19516143  0.11081398 -0.18124115 ... -0.23379877 -0.17233782\n",
            "  -0.06559834]\n",
            " [ 0.12552509 -0.11616872 -0.24824695 ... -0.19514878  0.14396971\n",
            "   0.19944572]\n",
            " [-0.18949562  0.05695605 -0.04643053 ...  0.23909575 -0.18545637\n",
            "  -0.13326782]]\n",
            "Layer 1 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "Layer 2 weights:\n",
            "[[-0.04592519  0.16149548  0.2661605  ...  0.1227676   0.09740803\n",
            "  -0.25465387]\n",
            " [-0.0345349   0.00765064  0.14407012 ... -0.09620075 -0.0836167\n",
            "  -0.19210565]\n",
            " [-0.27346712  0.16613987 -0.05279401 ... -0.06622843 -0.05518845\n",
            "  -0.11756724]\n",
            " ...\n",
            " [ 0.27078032  0.2515651  -0.14490372 ...  0.19142202  0.05811426\n",
            "  -0.1338444 ]\n",
            " [-0.12130079 -0.22523367  0.0833759  ... -0.24816819 -0.04546075\n",
            "  -0.18602517]\n",
            " [ 0.15957674 -0.11184588  0.03653359 ... -0.03061017 -0.15477186\n",
            "   0.05576357]]\n",
            "Layer 3 weights:\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "Layer 4 weights:\n",
            "[[-0.1122992 ]\n",
            " [ 0.26051682]\n",
            " [ 0.04460046]\n",
            " [ 0.06600165]\n",
            " [ 0.1865831 ]\n",
            " [-0.33339936]\n",
            " [ 0.2700613 ]\n",
            " [ 0.31785715]\n",
            " [ 0.13626683]\n",
            " [-0.41824365]\n",
            " [-0.29628983]\n",
            " [ 0.23142791]\n",
            " [-0.33347487]\n",
            " [ 0.39943886]\n",
            " [-0.18666562]\n",
            " [ 0.23091334]\n",
            " [ 0.20086694]\n",
            " [ 0.05474681]\n",
            " [ 0.43409634]\n",
            " [-0.2744587 ]\n",
            " [-0.05524442]\n",
            " [ 0.2517137 ]\n",
            " [-0.09705761]\n",
            " [-0.13922977]\n",
            " [-0.24642125]\n",
            " [ 0.4306956 ]\n",
            " [-0.14225617]\n",
            " [-0.06678936]\n",
            " [ 0.17088592]\n",
            " [-0.0148339 ]]\n",
            "Layer 5 weights:\n",
            "[0.]\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 3s 2ms/step - loss: 0.5715 - accuracy: 0.7163 - val_loss: 1.6133 - val_accuracy: 0.4657\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5550 - accuracy: 0.7271 - val_loss: 0.7163 - val_accuracy: 0.4657\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5518 - accuracy: 0.7296 - val_loss: 0.6677 - val_accuracy: 0.6003\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5496 - accuracy: 0.7305 - val_loss: 1.3813 - val_accuracy: 0.4657\n",
            "Epoch 5/100\n",
            "777/804 [===========================>..] - ETA: 0s - loss: 0.5488 - accuracy: 0.7300\n",
            "Epoch 5: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7300 - val_loss: 0.7964 - val_accuracy: 0.4657\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5476 - accuracy: 0.7321 - val_loss: 1.4251 - val_accuracy: 0.4657\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5473 - accuracy: 0.7310 - val_loss: 1.0799 - val_accuracy: 0.4657\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5467 - accuracy: 0.7332 - val_loss: 0.8057 - val_accuracy: 0.4657\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5458 - accuracy: 0.7319 - val_loss: 0.8602 - val_accuracy: 0.4657\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7314\n",
            "Epoch 10: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7314 - val_loss: 0.8189 - val_accuracy: 0.4657\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7329 - val_loss: 0.8129 - val_accuracy: 0.4657\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7320 - val_loss: 0.7465 - val_accuracy: 0.4657\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7348 - val_loss: 0.7695 - val_accuracy: 0.4657\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7343 - val_loss: 1.0532 - val_accuracy: 0.4657\n",
            "Epoch 15/100\n",
            "797/804 [============================>.] - ETA: 0s - loss: 0.5434 - accuracy: 0.7351\n",
            "Epoch 15: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5437 - accuracy: 0.7348 - val_loss: 1.0557 - val_accuracy: 0.4657\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7338 - val_loss: 1.0486 - val_accuracy: 0.4657\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7339 - val_loss: 0.7962 - val_accuracy: 0.4657\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7343 - val_loss: 0.8854 - val_accuracy: 0.4657\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7345 - val_loss: 0.8138 - val_accuracy: 0.4657\n",
            "Epoch 20/100\n",
            "800/804 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.7348\n",
            "Epoch 20: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7345 - val_loss: 0.8697 - val_accuracy: 0.4657\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5424 - accuracy: 0.7343 - val_loss: 0.8210 - val_accuracy: 0.4657\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7353 - val_loss: 0.7495 - val_accuracy: 0.4657\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7341 - val_loss: 0.8294 - val_accuracy: 0.4657\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5408 - accuracy: 0.7364 - val_loss: 0.8519 - val_accuracy: 0.4657\n",
            "Epoch 25/100\n",
            "785/804 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7356\n",
            "Epoch 25: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7356 - val_loss: 0.7530 - val_accuracy: 0.4657\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5410 - accuracy: 0.7352 - val_loss: 1.1095 - val_accuracy: 0.4657\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5407 - accuracy: 0.7361 - val_loss: 1.0947 - val_accuracy: 0.4657\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7353 - val_loss: 0.8450 - val_accuracy: 0.4657\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5404 - accuracy: 0.7368 - val_loss: 0.8399 - val_accuracy: 0.4657\n",
            "Epoch 30/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5404 - accuracy: 0.7346\n",
            "Epoch 30: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7346 - val_loss: 0.7653 - val_accuracy: 0.4657\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7352 - val_loss: 0.7599 - val_accuracy: 0.4657\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5400 - accuracy: 0.7375 - val_loss: 0.7667 - val_accuracy: 0.4657\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5393 - accuracy: 0.7371 - val_loss: 0.8495 - val_accuracy: 0.4657\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5398 - accuracy: 0.7363 - val_loss: 0.8538 - val_accuracy: 0.4657\n",
            "Epoch 35/100\n",
            "779/804 [============================>.] - ETA: 0s - loss: 0.5394 - accuracy: 0.7370\n",
            "Epoch 35: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5393 - accuracy: 0.7367 - val_loss: 1.1511 - val_accuracy: 0.4657\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7360 - val_loss: 0.8568 - val_accuracy: 0.4657\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7358 - val_loss: 0.8598 - val_accuracy: 0.4657\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7366 - val_loss: 0.8829 - val_accuracy: 0.4657\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7384 - val_loss: 0.9834 - val_accuracy: 0.4657\n",
            "Epoch 40/100\n",
            "788/804 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7358\n",
            "Epoch 40: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7360 - val_loss: 0.7047 - val_accuracy: 0.4657\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7367 - val_loss: 0.7686 - val_accuracy: 0.4657\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7381 - val_loss: 0.8885 - val_accuracy: 0.4657\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7363 - val_loss: 0.8987 - val_accuracy: 0.4657\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5382 - accuracy: 0.7363 - val_loss: 0.9092 - val_accuracy: 0.4657\n",
            "Epoch 45/100\n",
            "792/804 [============================>.] - ETA: 0s - loss: 0.5383 - accuracy: 0.7386\n",
            "Epoch 45: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5381 - accuracy: 0.7382 - val_loss: 0.8827 - val_accuracy: 0.4657\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5384 - accuracy: 0.7372 - val_loss: 1.0334 - val_accuracy: 0.4657\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5381 - accuracy: 0.7365 - val_loss: 1.0131 - val_accuracy: 0.4657\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7374 - val_loss: 1.5087 - val_accuracy: 0.4657\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7386 - val_loss: 1.5177 - val_accuracy: 0.4657\n",
            "Epoch 50/100\n",
            "796/804 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7379\n",
            "Epoch 50: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5378 - accuracy: 0.7380 - val_loss: 1.5525 - val_accuracy: 0.4657\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7385 - val_loss: 1.0422 - val_accuracy: 0.4657\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7376 - val_loss: 1.0240 - val_accuracy: 0.4657\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7372 - val_loss: 0.8900 - val_accuracy: 0.4657\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5371 - accuracy: 0.7381 - val_loss: 0.8433 - val_accuracy: 0.4657\n",
            "Epoch 55/100\n",
            "775/804 [===========================>..] - ETA: 0s - loss: 0.5383 - accuracy: 0.7365\n",
            "Epoch 55: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5372 - accuracy: 0.7373 - val_loss: 0.8607 - val_accuracy: 0.4657\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5370 - accuracy: 0.7368 - val_loss: 1.0294 - val_accuracy: 0.4657\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7384 - val_loss: 1.1954 - val_accuracy: 0.4657\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5366 - accuracy: 0.7377 - val_loss: 1.2090 - val_accuracy: 0.4657\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7381 - val_loss: 1.2196 - val_accuracy: 0.4657\n",
            "Epoch 60/100\n",
            "800/804 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.7376\n",
            "Epoch 60: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.7378 - val_loss: 1.2304 - val_accuracy: 0.4657\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7377 - val_loss: 1.1864 - val_accuracy: 0.4657\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7357 - val_loss: 1.0174 - val_accuracy: 0.4657\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7379 - val_loss: 1.2252 - val_accuracy: 0.4657\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7383 - val_loss: 0.7867 - val_accuracy: 0.4657\n",
            "Epoch 65/100\n",
            "791/804 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.7383\n",
            "Epoch 65: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7376 - val_loss: 0.7839 - val_accuracy: 0.4657\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5361 - accuracy: 0.7388 - val_loss: 0.7819 - val_accuracy: 0.4657\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5363 - accuracy: 0.7384 - val_loss: 0.8817 - val_accuracy: 0.4657\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5362 - accuracy: 0.7391 - val_loss: 0.8777 - val_accuracy: 0.4657\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7379 - val_loss: 0.7753 - val_accuracy: 0.4657\n",
            "Epoch 70/100\n",
            "791/804 [============================>.] - ETA: 0s - loss: 0.5359 - accuracy: 0.7384\n",
            "Epoch 70: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5359 - accuracy: 0.7384 - val_loss: 0.7676 - val_accuracy: 0.4657\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5359 - accuracy: 0.7394 - val_loss: 0.9364 - val_accuracy: 0.4657\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5357 - accuracy: 0.7395 - val_loss: 0.9313 - val_accuracy: 0.4657\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5359 - accuracy: 0.7378 - val_loss: 0.9174 - val_accuracy: 0.4657\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5356 - accuracy: 0.7396 - val_loss: 1.2397 - val_accuracy: 0.4657\n",
            "Epoch 75/100\n",
            "802/804 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.7383\n",
            "Epoch 75: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7384 - val_loss: 1.0419 - val_accuracy: 0.4657\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7383 - val_loss: 1.0562 - val_accuracy: 0.4657\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7393 - val_loss: 0.7695 - val_accuracy: 0.4657\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7378 - val_loss: 0.7353 - val_accuracy: 0.4657\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5355 - accuracy: 0.7389 - val_loss: 0.8619 - val_accuracy: 0.4657\n",
            "Epoch 80/100\n",
            "781/804 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7392\n",
            "Epoch 80: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5350 - accuracy: 0.7390 - val_loss: 0.8673 - val_accuracy: 0.4657\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5350 - accuracy: 0.7392 - val_loss: 1.0481 - val_accuracy: 0.4657\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5351 - accuracy: 0.7390 - val_loss: 0.8675 - val_accuracy: 0.4657\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5350 - accuracy: 0.7392 - val_loss: 0.8698 - val_accuracy: 0.4657\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7398 - val_loss: 0.8568 - val_accuracy: 0.4657\n",
            "Epoch 85/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.7386\n",
            "Epoch 85: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5353 - accuracy: 0.7387 - val_loss: 1.1441 - val_accuracy: 0.4657\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7383 - val_loss: 0.8510 - val_accuracy: 0.4657\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7387 - val_loss: 1.1693 - val_accuracy: 0.4657\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7399 - val_loss: 0.9234 - val_accuracy: 0.4657\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5345 - accuracy: 0.7384 - val_loss: 0.9707 - val_accuracy: 0.4657\n",
            "Epoch 90/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.7398\n",
            "Epoch 90: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7395 - val_loss: 1.1726 - val_accuracy: 0.4657\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5347 - accuracy: 0.7394 - val_loss: 1.1522 - val_accuracy: 0.4657\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5345 - accuracy: 0.7394 - val_loss: 1.1727 - val_accuracy: 0.4657\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7384 - val_loss: 0.9476 - val_accuracy: 0.4657\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5345 - accuracy: 0.7393 - val_loss: 1.1488 - val_accuracy: 0.4657\n",
            "Epoch 95/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5342 - accuracy: 0.7398\n",
            "Epoch 95: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5344 - accuracy: 0.7395 - val_loss: 1.1789 - val_accuracy: 0.4657\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7389 - val_loss: 1.1437 - val_accuracy: 0.4657\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5344 - accuracy: 0.7402 - val_loss: 1.1377 - val_accuracy: 0.4657\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5342 - accuracy: 0.7402 - val_loss: 0.9529 - val_accuracy: 0.4657\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7397 - val_loss: 1.1544 - val_accuracy: 0.4657\n",
            "Epoch 100/100\n",
            "780/804 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.7405\n",
            "Epoch 100: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5341 - accuracy: 0.7395 - val_loss: 1.1917 - val_accuracy: 0.4657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe2bea22e30>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Define the checkpoint file path\n",
        "checkpoint_filepath = 'model_weights2.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    period=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "weights = model2.get_weights()\n",
        "for i, layer_weights in enumerate(weights):\n",
        "    print(f'Layer {i} weights:')\n",
        "    print(layer_weights)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model2.fit(X_train_scaled, y_train,epochs=100,\n",
        "          validation_data=(X_test, y_test),\n",
        "    callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "815ABPmiMNgb",
        "outputId": "8758215b-dba1-483d-c452-58154cf5495e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5345 - accuracy: 0.7386 - val_loss: 1.1641 - val_accuracy: 0.4657\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5343 - accuracy: 0.7397 - val_loss: 0.9273 - val_accuracy: 0.4657\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7393 - val_loss: 1.1636 - val_accuracy: 0.4657\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5340 - accuracy: 0.7393 - val_loss: 1.1860 - val_accuracy: 0.4657\n",
            "Epoch 5/100\n",
            "791/804 [============================>.] - ETA: 0s - loss: 0.5335 - accuracy: 0.7389\n",
            "Epoch 5: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5339 - accuracy: 0.7386 - val_loss: 1.1498 - val_accuracy: 0.4657\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5340 - accuracy: 0.7394 - val_loss: 1.2551 - val_accuracy: 0.4657\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7397 - val_loss: 1.1492 - val_accuracy: 0.4657\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5339 - accuracy: 0.7400 - val_loss: 1.1137 - val_accuracy: 0.4657\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5343 - accuracy: 0.7397 - val_loss: 1.1730 - val_accuracy: 0.4657\n",
            "Epoch 10/100\n",
            "794/804 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.7389\n",
            "Epoch 10: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5340 - accuracy: 0.7391 - val_loss: 1.5132 - val_accuracy: 0.4657\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5343 - accuracy: 0.7398 - val_loss: 1.1573 - val_accuracy: 0.4657\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7388 - val_loss: 1.1743 - val_accuracy: 0.4657\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7405 - val_loss: 1.1741 - val_accuracy: 0.4657\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5336 - accuracy: 0.7400 - val_loss: 1.2231 - val_accuracy: 0.4657\n",
            "Epoch 15/100\n",
            "783/804 [============================>.] - ETA: 0s - loss: 0.5341 - accuracy: 0.7391\n",
            "Epoch 15: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5338 - accuracy: 0.7393 - val_loss: 0.9345 - val_accuracy: 0.4657\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5336 - accuracy: 0.7403 - val_loss: 1.2083 - val_accuracy: 0.4657\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5335 - accuracy: 0.7405 - val_loss: 1.0395 - val_accuracy: 0.4657\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7404 - val_loss: 0.7592 - val_accuracy: 0.4657\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7406 - val_loss: 1.2396 - val_accuracy: 0.4657\n",
            "Epoch 20/100\n",
            "796/804 [============================>.] - ETA: 0s - loss: 0.5333 - accuracy: 0.7394\n",
            "Epoch 20: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7394 - val_loss: 1.5331 - val_accuracy: 0.4657\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5336 - accuracy: 0.7400 - val_loss: 1.1687 - val_accuracy: 0.4657\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5334 - accuracy: 0.7396 - val_loss: 1.4716 - val_accuracy: 0.4657\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5334 - accuracy: 0.7408 - val_loss: 1.4538 - val_accuracy: 0.4657\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7401 - val_loss: 1.4631 - val_accuracy: 0.4657\n",
            "Epoch 25/100\n",
            "783/804 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.7413\n",
            "Epoch 25: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5334 - accuracy: 0.7409 - val_loss: 1.4496 - val_accuracy: 0.4657\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7400 - val_loss: 1.4565 - val_accuracy: 0.4657\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5330 - accuracy: 0.7408 - val_loss: 1.4840 - val_accuracy: 0.4657\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7404 - val_loss: 1.4726 - val_accuracy: 0.4657\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5336 - accuracy: 0.7398 - val_loss: 1.2637 - val_accuracy: 0.4657\n",
            "Epoch 30/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5330 - accuracy: 0.7402\n",
            "Epoch 30: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5329 - accuracy: 0.7400 - val_loss: 1.1667 - val_accuracy: 0.4657\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5333 - accuracy: 0.7404 - val_loss: 1.5871 - val_accuracy: 0.4657\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5338 - accuracy: 0.7398 - val_loss: 1.4319 - val_accuracy: 0.4657\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7399 - val_loss: 1.2469 - val_accuracy: 0.4657\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5333 - accuracy: 0.7408 - val_loss: 0.9152 - val_accuracy: 0.4657\n",
            "Epoch 35/100\n",
            "796/804 [============================>.] - ETA: 0s - loss: 0.5331 - accuracy: 0.7401\n",
            "Epoch 35: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5330 - accuracy: 0.7400 - val_loss: 1.1793 - val_accuracy: 0.4657\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5330 - accuracy: 0.7407 - val_loss: 1.4559 - val_accuracy: 0.4657\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7406 - val_loss: 1.2218 - val_accuracy: 0.4657\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5329 - accuracy: 0.7412 - val_loss: 1.1502 - val_accuracy: 0.4657\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7401 - val_loss: 1.1557 - val_accuracy: 0.4657\n",
            "Epoch 40/100\n",
            "797/804 [============================>.] - ETA: 0s - loss: 0.5324 - accuracy: 0.7403\n",
            "Epoch 40: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.7402 - val_loss: 1.2611 - val_accuracy: 0.4657\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5331 - accuracy: 0.7396 - val_loss: 0.9967 - val_accuracy: 0.4657\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5331 - accuracy: 0.7402 - val_loss: 1.2847 - val_accuracy: 0.4657\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7405 - val_loss: 1.2704 - val_accuracy: 0.4657\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5329 - accuracy: 0.7406 - val_loss: 0.9793 - val_accuracy: 0.4657\n",
            "Epoch 45/100\n",
            "793/804 [============================>.] - ETA: 0s - loss: 0.5330 - accuracy: 0.7405\n",
            "Epoch 45: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5330 - accuracy: 0.7405 - val_loss: 0.9120 - val_accuracy: 0.4657\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5334 - accuracy: 0.7394 - val_loss: 0.9235 - val_accuracy: 0.4657\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5331 - accuracy: 0.7404 - val_loss: 0.9005 - val_accuracy: 0.4657\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5327 - accuracy: 0.7406 - val_loss: 1.1724 - val_accuracy: 0.4657\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5331 - accuracy: 0.7404 - val_loss: 1.1713 - val_accuracy: 0.4657\n",
            "Epoch 50/100\n",
            "797/804 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7405\n",
            "Epoch 50: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7401 - val_loss: 1.1465 - val_accuracy: 0.4657\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7399 - val_loss: 1.4520 - val_accuracy: 0.4657\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.7402 - val_loss: 1.4943 - val_accuracy: 0.4657\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5331 - accuracy: 0.7401 - val_loss: 1.1284 - val_accuracy: 0.4657\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5330 - accuracy: 0.7401 - val_loss: 1.1395 - val_accuracy: 0.4657\n",
            "Epoch 55/100\n",
            "803/804 [============================>.] - ETA: 0s - loss: 0.5334 - accuracy: 0.7400\n",
            "Epoch 55: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7400 - val_loss: 0.9943 - val_accuracy: 0.4657\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7395 - val_loss: 1.2890 - val_accuracy: 0.4657\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7404 - val_loss: 1.4853 - val_accuracy: 0.4657\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5329 - accuracy: 0.7403 - val_loss: 1.1854 - val_accuracy: 0.4657\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5331 - accuracy: 0.7400 - val_loss: 1.0862 - val_accuracy: 0.4657\n",
            "Epoch 60/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5330 - accuracy: 0.7400\n",
            "Epoch 60: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5326 - accuracy: 0.7402 - val_loss: 0.8967 - val_accuracy: 0.4657\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.7410 - val_loss: 0.8662 - val_accuracy: 0.4657\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.7410 - val_loss: 0.8907 - val_accuracy: 0.4657\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7407 - val_loss: 0.8858 - val_accuracy: 0.4657\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5325 - accuracy: 0.7399 - val_loss: 1.4515 - val_accuracy: 0.4657\n",
            "Epoch 65/100\n",
            "798/804 [============================>.] - ETA: 0s - loss: 0.5326 - accuracy: 0.7406\n",
            "Epoch 65: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5325 - accuracy: 0.7408 - val_loss: 1.4351 - val_accuracy: 0.4657\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5329 - accuracy: 0.7400 - val_loss: 1.7646 - val_accuracy: 0.4657\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7400 - val_loss: 0.8805 - val_accuracy: 0.4657\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7407 - val_loss: 0.7601 - val_accuracy: 0.4657\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7406 - val_loss: 0.9184 - val_accuracy: 0.4657\n",
            "Epoch 70/100\n",
            "795/804 [============================>.] - ETA: 0s - loss: 0.5330 - accuracy: 0.7402\n",
            "Epoch 70: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5327 - accuracy: 0.7405 - val_loss: 0.9029 - val_accuracy: 0.4657\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5328 - accuracy: 0.7400 - val_loss: 1.1911 - val_accuracy: 0.4657\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5327 - accuracy: 0.7396 - val_loss: 0.9019 - val_accuracy: 0.4657\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5326 - accuracy: 0.7402 - val_loss: 0.7459 - val_accuracy: 0.4657\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5326 - accuracy: 0.7400 - val_loss: 0.7546 - val_accuracy: 0.4657\n",
            "Epoch 75/100\n",
            "799/804 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7408\n",
            "Epoch 75: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5324 - accuracy: 0.7408 - val_loss: 0.7908 - val_accuracy: 0.4657\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7406 - val_loss: 0.7287 - val_accuracy: 0.4657\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5325 - accuracy: 0.7410 - val_loss: 1.0458 - val_accuracy: 0.4657\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7406 - val_loss: 0.9123 - val_accuracy: 0.4657\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5327 - accuracy: 0.7411 - val_loss: 0.9735 - val_accuracy: 0.4657\n",
            "Epoch 80/100\n",
            "782/804 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.7407\n",
            "Epoch 80: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7410 - val_loss: 0.7991 - val_accuracy: 0.4657\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7398 - val_loss: 0.6836 - val_accuracy: 0.5343\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5321 - accuracy: 0.7406 - val_loss: 0.7250 - val_accuracy: 0.4657\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5326 - accuracy: 0.7400 - val_loss: 0.7723 - val_accuracy: 0.4657\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5323 - accuracy: 0.7406 - val_loss: 0.7614 - val_accuracy: 0.4657\n",
            "Epoch 85/100\n",
            "790/804 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.7409\n",
            "Epoch 85: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7405 - val_loss: 0.7686 - val_accuracy: 0.4657\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7409 - val_loss: 0.7146 - val_accuracy: 0.4657\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5317 - accuracy: 0.7408 - val_loss: 0.7146 - val_accuracy: 0.4657\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5318 - accuracy: 0.7406 - val_loss: 1.1037 - val_accuracy: 0.4657\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7409 - val_loss: 0.9108 - val_accuracy: 0.4657\n",
            "Epoch 90/100\n",
            "791/804 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7401\n",
            "Epoch 90: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5327 - accuracy: 0.7400 - val_loss: 0.8508 - val_accuracy: 0.4657\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7404 - val_loss: 0.9630 - val_accuracy: 0.4657\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7406 - val_loss: 0.9106 - val_accuracy: 0.4657\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5320 - accuracy: 0.7400 - val_loss: 0.8973 - val_accuracy: 0.4657\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5321 - accuracy: 0.7405 - val_loss: 0.9149 - val_accuracy: 0.4657\n",
            "Epoch 95/100\n",
            "776/804 [===========================>..] - ETA: 0s - loss: 0.5312 - accuracy: 0.7415\n",
            "Epoch 95: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7408 - val_loss: 0.7123 - val_accuracy: 0.4657\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7409 - val_loss: 0.7189 - val_accuracy: 0.4657\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5319 - accuracy: 0.7406 - val_loss: 0.7196 - val_accuracy: 0.4657\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5320 - accuracy: 0.7407 - val_loss: 0.7190 - val_accuracy: 0.4657\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5317 - accuracy: 0.7401 - val_loss: 0.7262 - val_accuracy: 0.4657\n",
            "Epoch 100/100\n",
            "784/804 [============================>.] - ETA: 0s - loss: 0.5318 - accuracy: 0.7410\n",
            "Epoch 100: saving model to model_weights2.h5\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5323 - accuracy: 0.7406 - val_loss: 0.7215 - val_accuracy: 0.4657\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the checkpoint file path\n",
        "checkpoint_filepath = 'model_weights2.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    period=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model2.fit(X_train_scaled, y_train,\n",
        "                     epochs=100,\n",
        "                     validation_data=(X_test, y_test),\n",
        "                     callbacks=[checkpoint_callback])\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_fVJGrl1vVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0767285-1a41-41ec-f608-da95af98354a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5573 - accuracy: 0.7275 - 343ms/epoch - 1ms/step\n",
            "Loss: 0.5573437809944153, Accuracy: 0.7274635434150696\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = model2.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-tJgbop1_5G"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Export our model to HDF5 file\n",
        "# save the model to an HDF5 file\n",
        "model.save('AlphabetSoupCharity2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyYWNSu4Aluk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "5e1bad45-dadc-4ad8-cba7-84a7e60fb1a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                     0.0   \n",
              "1       1   108590              1                     0.0   \n",
              "2       1     5000              0                     0.0   \n",
              "3       1     6692              1                     0.0   \n",
              "4       1   142590              1                     0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                   1.0                   0.0                  0.0   \n",
              "1                   0.0                   0.0                  1.0   \n",
              "2                   0.0                   0.0                  0.0   \n",
              "3                   0.0                   0.0                  1.0   \n",
              "4                   0.0                   0.0                  1.0   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                  0.0                  0.0                  0.0  ...   \n",
              "1                  0.0                  0.0                  0.0  ...   \n",
              "2                  0.0                  1.0                  0.0  ...   \n",
              "3                  0.0                  0.0                  0.0  ...   \n",
              "4                  0.0                  0.0                  0.0  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                0.0                     0.0                       0.0   \n",
              "1                1.0                     0.0                       0.0   \n",
              "2                0.0                     0.0                       0.0   \n",
              "3                0.0                     1.0                       0.0   \n",
              "4                0.0                     0.0                       1.0   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                 0.0               0.0                     0.0   \n",
              "1                 0.0               0.0                     0.0   \n",
              "2                 0.0               0.0                     0.0   \n",
              "3                 0.0               0.0                     0.0   \n",
              "4                 0.0               0.0                     0.0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0              0.0                0.0                       1.0   \n",
              "1              0.0                0.0                       1.0   \n",
              "2              0.0                0.0                       1.0   \n",
              "3              0.0                0.0                       1.0   \n",
              "4              0.0                0.0                       1.0   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                       0.0  \n",
              "1                       0.0  \n",
              "2                       0.0  \n",
              "3                       0.0  \n",
              "4                       0.0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-401ee6d0-b51f-4d33-b7fa-1b5dd7b00768\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-401ee6d0-b51f-4d33-b7fa-1b5dd7b00768')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-401ee6d0-b51f-4d33-b7fa-1b5dd7b00768 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-401ee6d0-b51f-4d33-b7fa-1b5dd7b00768');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "application_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r3GdJHQD7MC"
      },
      "source": [
        "The accuracy of the model is 0.7266, which means it correctly predicts the outcome for 72.66% of the cases in the test set. While this is not a bad accuracy, whether this model is considered \"good\" or not depends on the specific context and requirements of the project.\n",
        "\n",
        "For example, if the consequences of a false positive (predicting a success when it will actually fail) or a false negative (predicting a failure when it will actually succeed) are very different, then the accuracy alone may not be a sufficient metric to evaluate the model's performance.\n",
        "\n",
        "It's important to also consider other metrics such as precision, recall, F1-score, and the confusion matrix to get a better understanding of the model's performance. Additionally, if the project requirements demand a higher accuracy, then further optimization may be necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFl3VIb26u9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf2389e-4dde-476b-be84-19530a5a0142"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    18261\n",
              "0    16038\n",
              "Name: IS_SUCCESSFUL, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#look at the confusion matrix to determine if a 72% is a good \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "X = application_df.drop('IS_SUCCESSFUL',axis=1)\n",
        "\n",
        "# Check the balance of our target values\n",
        "label_counts = y.value_counts()\n",
        "label_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bueNND-cBLFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a9a20d-97e9-462c-e5f0-529a67ebaf87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 1s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make a prediction using the testing data\n",
        "pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlzomogWBmQA"
      },
      "outputs": [],
      "source": [
        "# predictions_df = pd.DataFrame({\"Prediction\": pred, \"Actual\": y_test})\n",
        "# predictions_df.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6HYL6EFmvcR83RIZVVshP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}